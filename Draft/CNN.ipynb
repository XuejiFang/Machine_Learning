{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc649ba-d5f9-41bc-b93e-9db3a9885198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880a8d89-bec1-47d7-a490-2ff2d725be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper prameters\n",
    "EPOCH=1\n",
    "BATCH_SIZE=50\n",
    "LR=0.001\n",
    "DOWNLOAD_MNIST=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0bf6e8-990c-4f86-8c9e-ef95952ecf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%\n",
      "/opt/conda/envs/pytorch1.8/lib/python3.9/site-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1614378073850/work/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data=torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),    #将下载的文件转换成pytorch认识的tensor类型，且将图片的数值大小从（0-255）归一化到（0-1）\n",
    "    download=DOWNLOAD_MNIST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a955695a-af16-4a3d-95ae-3ad2b8c8e039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#画一个图片显示出来\n",
    "print(train_data.data.size())\n",
    "print(train_data.targets.size())\n",
    "plt.imshow(train_data.data[0].numpy(),cmap='gray')\n",
    "plt.title('%i'%train_data.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4380ca88-14c5-46c6-92a2-5f5a3f2e2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ab3aca-ab2e-4a13-9421-8885f537b99f",
   "metadata": {},
   "source": [
    "> 设置较大的 batch_size 可能会提高训练速度，但是同时也会增加内存使用量。相反，设置较小的 batch_size 可能会减慢训练速度，但是同时会减少内存使用量。因此，需要根据实际情况来调整 batch_size 的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dde539e-1418-4537-8001-dab60d2630d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c83778-ee67-4685-9603-1c2dc17f8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_x=Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.FloatTensor)[:2000]/255   #只取前两千个数据吧，差不多已经够用了，然后将其归一化。\n",
    "    test_y=test_data.targets[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "371745fb-7670-4f40-b4e8-4ec53401d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''开始建立CNN网络'''\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        '''\n",
    "        一般来说，卷积网络包括以下内容：\n",
    "        1.卷积层\n",
    "        2.神经网络\n",
    "        3.池化层\n",
    "        '''\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(              #--> (1,28,28)\n",
    "                in_channels=1,      #传入的图片是几层的，灰色为1层，RGB为三层\n",
    "                out_channels=16,    #输出的图片是几层\n",
    "                kernel_size=5,      #代表扫描的区域点为5*5\n",
    "                stride=1,           #就是每隔多少步跳一下\n",
    "                padding=2,          #边框补全，其计算公式=（kernel_size-1）/2=(5-1)/2=2\n",
    "            ),    # 2d代表二维卷积           --> (16,28,28)\n",
    "            nn.ReLU(),              #非线性激活层\n",
    "            nn.MaxPool2d(kernel_size=2),    #设定这里的扫描区域为2*2，且取出该2*2中的最大值          --> (16,14,14)\n",
    "        )\n",
    "\n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv2d(              #       --> (16,14,14)\n",
    "                in_channels=16,     #这里的输入是上层的输出为16层\n",
    "                out_channels=32,    #在这里我们需要将其输出为32层\n",
    "                kernel_size=5,      #代表扫描的区域点为5*5\n",
    "                stride=1,           #就是每隔多少步跳一下\n",
    "                padding=2,          #边框补全，其计算公式=（kernel_size-1）/2=(5-1)/2=\n",
    "            ),                      #   --> (32,14,14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),    #设定这里的扫描区域为2*2，且取出该2*2中的最大值     --> (32,7,7)，这里是三维数据\n",
    "        )\n",
    "\n",
    "        self.out=nn.Linear(32*7*7,10)       #注意一下这里的数据是二维的数据\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)     #（batch,32,7,7）\n",
    "        #然后接下来进行一下扩展展平的操作，将三维数据转为二维的数据\n",
    "        x=x.view(x.size(0),-1)    #(batch ,32 * 7 * 7)\n",
    "        output=self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b81d255-d0c9-4bc3-8501-f69d664213ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn=CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16b14ebd-06e7-4106-8bd7-87e8649af21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加优化方法\n",
    "optimizer=torch.optim.Adam(cnn.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "600db376-700c-4cee-a7fe-e79198bb365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定损失函数使用交叉信息熵\n",
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd44c0b1-0b16-4061-9a59-d0268dc55988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now epoch :   0    |  loss : 2.2950       |   accuracy :    0.1545\n",
      "now epoch :   0    |  loss : 0.4004       |   accuracy :    0.829\n",
      "now epoch :   0    |  loss : 0.1852       |   accuracy :    0.879\n",
      "now epoch :   0    |  loss : 0.1992       |   accuracy :    0.9155\n",
      "now epoch :   0    |  loss : 0.1494       |   accuracy :    0.933\n",
      "now epoch :   0    |  loss : 0.1291       |   accuracy :    0.9395\n",
      "now epoch :   0    |  loss : 0.2756       |   accuracy :    0.9415\n",
      "now epoch :   0    |  loss : 0.1251       |   accuracy :    0.956\n",
      "now epoch :   0    |  loss : 0.1288       |   accuracy :    0.9515\n",
      "now epoch :   0    |  loss : 0.1385       |   accuracy :    0.949\n",
      "now epoch :   0    |  loss : 0.0505       |   accuracy :    0.9655\n",
      "now epoch :   0    |  loss : 0.1386       |   accuracy :    0.971\n",
      "now epoch :   0    |  loss : 0.1096       |   accuracy :    0.963\n",
      "now epoch :   0    |  loss : 0.1424       |   accuracy :    0.9685\n",
      "now epoch :   0    |  loss : 0.0925       |   accuracy :    0.971\n",
      "now epoch :   0    |  loss : 0.1690       |   accuracy :    0.9725\n",
      "now epoch :   0    |  loss : 0.0957       |   accuracy :    0.9675\n",
      "now epoch :   0    |  loss : 0.0269       |   accuracy :    0.9715\n",
      "now epoch :   0    |  loss : 0.0892       |   accuracy :    0.977\n",
      "now epoch :   0    |  loss : 0.1469       |   accuracy :    0.969\n",
      "now epoch :   0    |  loss : 0.0125       |   accuracy :    0.976\n",
      "now epoch :   0    |  loss : 0.1050       |   accuracy :    0.976\n",
      "now epoch :   0    |  loss : 0.0226       |   accuracy :    0.9735\n",
      "now epoch :   0    |  loss : 0.4123       |   accuracy :    0.9725\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "开始训练我们的模型哦\n",
    "'''\n",
    "step=0\n",
    "for epoch in range(EPOCH):\n",
    "    #加载训练数据\n",
    "    for step,data in enumerate(train_loader):\n",
    "        x,y=data\n",
    "        #分别得到训练数据的x和y的取值\n",
    "        b_x=Variable(x)\n",
    "        b_y=Variable(y)\n",
    "\n",
    "        output=cnn(b_x)         #调用模型预测\n",
    "        loss=loss_fn(output,b_y)#计算损失值\n",
    "        optimizer.zero_grad()   #每一次循环之前，将梯度清零\n",
    "        loss.backward()         #反向传播\n",
    "        optimizer.step()        #梯度下降\n",
    "\n",
    "        #每执行50次，输出一下当前epoch、loss、accuracy\n",
    "        if (step%50==0):\n",
    "            #计算一下模型预测正确率\n",
    "            test_output=cnn(test_x)\n",
    "            y_pred=torch.max(test_output,1)[1].data.squeeze()\n",
    "            accuracy=sum(y_pred==test_y).item()/test_y.size(0)\n",
    "\n",
    "            print('now epoch :  ', epoch, '   |  loss : %.4f ' % loss.item(), '     |   accuracy :   ' , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f121856f-88d6-47c6-ab9e-5db7b302771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9] predecton Result\n",
      "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9] Real Result\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "打印十个测试集的结果\n",
    "'''\n",
    "test_output=cnn(test_x[:10])\n",
    "y_pred=torch.max(test_output,1)[1].data.squeeze()       #选取最大可能的数值所在的位置\n",
    "print(y_pred.tolist(),'predecton Result')\n",
    "print(test_y[:10].tolist(),'Real Result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67bf33-835f-4905-ab45-1b5627aaeee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.8",
   "language": "python",
   "name": "torch1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
