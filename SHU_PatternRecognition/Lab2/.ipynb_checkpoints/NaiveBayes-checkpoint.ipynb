{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e25ebee",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "**结论**\n",
    "\n",
    "1. 实现了基于离散属性和连续属性的朴素贝叶斯分类器\n",
    "2. 进行了二项检验、t检验、交叉验证t检验、McNemar检验，得出以下结论：\n",
    "    1. 通过二项检验发现，对于离散属性的朴素贝叶斯分类器，在**90%的置信水平**下，认为模型分**泛化错误率小于10%**\n",
    "    2. 通过t检验发现，对于离散属性的朴素贝叶斯分类器，在以**90%的置信度**下，认为模型的**泛化错误率等于8%**\n",
    "    3. 通过交叉验证t检验发现，离散属性的朴素贝叶斯分类器的性能比连续属性的更优（**未考虑到独立采样**）\n",
    "    4. 通过$5\\times 2$折交叉验证t检验发现，两者性能**没有显著差别**\n",
    "    5. 通过McNemar检验发现，两者性能**没有显著差别**\n",
    "    \n",
    "\n",
    "**数据**\n",
    "\n",
    "    - 2021冬模式识别数据收集.xlsx\n",
    "   \n",
    "> 说明:\n",
    ">\n",
    "> 以身高、体重、脚长、尺码来判断性别\n",
    ">\n",
    "> 以上特征可以视为离散型属性，亦可以视为连续型属性\n",
    " \n",
    " **优点**：小样本，多分类\n",
    "\n",
    "**缺点**：对于输入数据敏感\n",
    "\n",
    "**公式**\n",
    "\n",
    "\n",
    "$$\n",
    "P(c|x)=\\frac{p(c,x)}{p(x)}=\\frac{P(c)p(x|c)}{p(x)}=\\frac{P(c)}{p(x)}\\prod_{i=1}^{d}{P(x_i|c)}\n",
    "$$\n",
    "\n",
    "\n",
    "对于所有类别来说，$P(x)$一样，因此只考虑分子部分\n",
    "\n",
    "$$\n",
    "h_{nb}=arg\\ max_{c\\in \\gamma}P(c)\\prod_{i=1}^d{P(x_i|c)}\n",
    "$$\n",
    "\n",
    "**先验概率**\n",
    "\n",
    "采用频率估计\n",
    "$$\n",
    "P(c)=\\frac{|D_c|}{|D|}\n",
    "$$\n",
    "\n",
    "**条件概率**\n",
    "\n",
    "\n",
    "1. 离散\n",
    "$$\n",
    "p(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}\n",
    "$$\n",
    "\n",
    "> 拉普拉斯修正 $p(c)=\\frac{|D_c|+1}{|D|+N}$\n",
    "\n",
    "\n",
    "2. 连续\n",
    "\n",
    "> 假设$p(x_i|c)\\sim N(\\mu_{c,i},\\sigma_{c,i}^2)$\n",
    "\n",
    "$$\n",
    "p(x_i|c)=\\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}} exp(-\\frac{(x_i-\\mu_{c,i})^2}{2\\sigma_{c,i}^2})\n",
    "$$\n",
    " \n",
    " **环境**\n",
    " \n",
    " ```shell\n",
    " Python                         3.8.4\n",
    " matplotlib                     3.5.2\n",
    " numpy                          1.22.4\n",
    " pandas                         1.3.5\n",
    " scikit-learn                   1.1.1\n",
    " seaborn                        0.11.2\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8da53",
   "metadata": {},
   "source": [
    "## 1. 导入包和模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b294c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from collections import Counter\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e176ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fileName):\n",
    "    data = pd.read_excel(fileName,index_col=0)\n",
    "    data = data.dropna(axis=1)\n",
    "    data['性别'] = data['性别'].map({'男':0,'女':1})\n",
    "    # sns.pairplot(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1090abc",
   "metadata": {},
   "source": [
    "## 2. 离散属性的朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab7e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义朴素贝叶斯分类器-离散型\n",
    "class NaiveBayesClassifierDiscrete:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.prior_prob = None\n",
    "        self.conditional_prob = None\n",
    "        self.num_values = None\n",
    "\n",
    "    # 训练函数\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 计算先验概率和条件概率        \n",
    "        parameters:\n",
    "            - data 训练特征矩阵\n",
    "            - labels 训练标签向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        # 计算先验概率\n",
    "        label_counts = Counter(labels)  # 计算每个标签的数量\n",
    "        num_samples = len(labels)  # 计算样本总数\n",
    "        self.prior_prob = {label: count / num_samples for label, count in label_counts.items()}  # 计算每个标签的先验概率\n",
    "\n",
    "        # 计算条件概率\n",
    "        self.conditional_prob = {}\n",
    "        self.num_values = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.conditional_prob[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                self.conditional_prob[label][feature_index] = {}\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                value_counts = Counter(feature_values)  # 统计每个特征值出现的次数\n",
    "                self.num_values[feature_index] = len(feature_values)  # 该特征值出现的总次数\n",
    "                # self.conditional_prob[label][feature_index] = {value: count / num_values for value, count in value_counts.items()}  # 计算每个特征值的条件概率\n",
    "                # 拉普拉斯变换修正\n",
    "                self.conditional_prob[label][feature_index] = {value: (count+1) / (2 * self.num_values[feature_index]) for value, count in value_counts.items()}  # 计算每个特征值的条件概率\n",
    "        \n",
    "\n",
    "    # 预测函数\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 给定特征值，预测类别\n",
    "        parameters:\n",
    "            - data 测试特征向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        for sample in data:\n",
    "            # 计算每个标签的概率\n",
    "            label_prob = {label: self.prior_prob[label] for label in self.prior_prob.keys()}\n",
    "            for label in self.prior_prob.keys():\n",
    "                for feature_index in range(len(sample)):\n",
    "                    feature_value = sample[feature_index]\n",
    "                    if feature_value in self.conditional_prob[label][feature_index].keys():\n",
    "                        label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    else:\n",
    "                        # label_prob[label] = 0\n",
    "                        # 拉普拉斯修正\n",
    "                        label_prob[label] *= 1 / (2*self.num_values[feature_index])\n",
    "            # 根据概率选择最大的标签\n",
    "            labels.append(max(label_prob, key=label_prob.get))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99761bc3",
   "metadata": {},
   "source": [
    "## 3. 连续属性的朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae43db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义朴素贝叶斯分类器-连续型\n",
    "class NaiveBayesClassifierContinuous:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.prior_prob = None\n",
    "        self.conditional_prob = None\n",
    "        self.num_values = None\n",
    "        self.mu = None\n",
    "        self.std = None\n",
    "    \n",
    "    def gauss(self, x, mu, std):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 计算高斯函数值\n",
    "        parameters:\n",
    "            - mu 均值\n",
    "            - std 标准差\n",
    "        return:\n",
    "            - ans 函数值\n",
    "        \"\"\"\n",
    "        ans = 1/(np.sqrt(2*np.pi)*std)*np.exp(-(x-mu)**2/(2*(std**2)))\n",
    "        return ans\n",
    "\n",
    "    # 训练函数\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 计算先验概率和条件概率        \n",
    "        parameters:\n",
    "            - data 训练特征矩阵\n",
    "            - labels 训练标签向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        # 计算先验概率\n",
    "        label_counts = Counter(labels)  # 计算每个标签的数量\n",
    "        num_samples = len(labels)  # 计算样本总数\n",
    "        self.prior_prob = {label: count / num_samples for label, count in label_counts.items()}  # 计算每个标签的先验概率\n",
    "        \n",
    "        # 计算每个标签的第i个特征的均值mu和标准差std\n",
    "        # 用样本均值和标准差来进行估计\n",
    "        self.mu = {}; self.std = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.mu[label] = {}; self.std[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                mu = np.mean(feature_values); std = np.std(feature_values)\n",
    "                self.mu[label][feature_index] = mu\n",
    "                self.std[label][feature_index] = std\n",
    "        \n",
    "    \n",
    "        # 计算条件概率\n",
    "        self.conditional_prob = {}\n",
    "        self.num_values = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.conditional_prob[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                self.num_values[feature_index] = len(feature_values)\n",
    "                value_counts = Counter(feature_values)\n",
    "                self.conditional_prob[label][feature_index] = {value: self.gauss(value, self.mu[label][feature_index], self.std[label][feature_index]) for value in value_counts.keys()}\n",
    "        return self\n",
    "    # 预测函数\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 给定特征值，预测类别\n",
    "        parameters:\n",
    "            - data 测试特征向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        for sample in data:\n",
    "            # 计算每个标签的概率\n",
    "            label_prob = {label: self.prior_prob[label] for label in self.prior_prob.keys()}\n",
    "            for label in self.prior_prob.keys():\n",
    "                for feature_index in range(len(sample)):\n",
    "                    feature_value = sample[feature_index]\n",
    "                    # label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    if feature_value in self.conditional_prob[label][feature_index].keys():\n",
    "                        label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    else:\n",
    "                        # label_prob[label] = 0\n",
    "                        # 拉普拉斯修正\n",
    "                        label_prob[label] *= 1 / (2*self.num_values[feature_index])\n",
    "            # 根据概率选择最大的标签\n",
    "            labels.append(max(label_prob, key=label_prob.get))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53ced5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_C:\t [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]\n",
      "y_pred_D:\t [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]\n",
      "y_test:\t\t [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    fileName = './work/2021冬模式识别数据收集.xlsx'\n",
    "    data = load_data(fileName)\n",
    "    X = data.iloc[:, 1:]\n",
    "    y = data.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "    X_train = X_train.values; X_test = X_test.values\n",
    "    y_train = y_train.values; y_test = y_test.values\n",
    "    NBC = NaiveBayesClassifierContinuous()\n",
    "    NBD = NaiveBayesClassifierDiscrete()\n",
    "    NBC.data = X_train; NBC.labels = y_train\n",
    "    NBD.data = X_train; NBD.labels = y_train\n",
    "    NBC.fit(X_train, y_train); NBD.fit(X_train, y_train)\n",
    "    y_pred_C = NBC.predict(X_test)\n",
    "    y_pred_D = NBD.predict(X_test)\n",
    "    print('y_pred_C:\\t', y_pred_C)\n",
    "    print('y_pred_D:\\t', y_pred_D)\n",
    "    print('y_test:\\t\\t', list(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7023e",
   "metadata": {},
   "source": [
    "## 4. 比较检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572e02f",
   "metadata": {},
   "source": [
    "### 4.1. 二项检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbfae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456f63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values; X_test = X_test.values\n",
    "y_train = y_train.values; y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258fab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBD.fit(X_train, y_train)\n",
    "y_pred = NBD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a61c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "errCount = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        errCount += 1\n",
    "errRate = errCount/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a384c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09090909090909091"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c690b",
   "metadata": {},
   "source": [
    "> 假设模型的泛化错误率小于10%，\n",
    ">\n",
    "> 即$H_0: \\epsilon < 0.1$\n",
    ">\n",
    "$$\n",
    "P(\\hat{\\epsilon};\\epsilon)=C_{m}^n \\epsilon^m(1-\\epsilon)^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d197d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c37fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b24bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "epsilon = 0.1\n",
    "for n in range(m+1):\n",
    "    p = math.comb(m, n)*(epsilon**n)*((1-epsilon)**(m-n))\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f563bd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "130a2d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(list(range(m+1)),P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cac205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000006e-11\n",
      "1.0000000000000005e-09\n",
      "4.555000000000003e-08\n",
      "1.2484000000000008e-06\n",
      "2.2899700000000007e-05\n",
      "0.00029570608000000013\n",
      "0.002750963500000001\n",
      "0.01853476120000001\n",
      "0.08956185085000004\n",
      "0.30264311980000014\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "acc = 0\n",
    "for i in reversed(list(range(m+1))):\n",
    "    acc += P[i]\n",
    "    print(acc)\n",
    "    if acc > alpha:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cdedfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc25d3",
   "metadata": {},
   "source": [
    "> 落在置信区间内\n",
    ">\n",
    "> 以90%的置信水平认为，模型分泛化错误率小于10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a5504",
   "metadata": {},
   "source": [
    "### 4.2. t检验 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e90b547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "691fcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "errRate = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    NBD.fit(X_train, y_train)\n",
    "    y_pred = NBD.predict(X_test)\n",
    "    errCount = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred[i] != y_test[i]:\n",
    "            errCount += 1\n",
    "    errRate.append(errCount/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75b11dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09090909090909091, 0.0, 0.1, 0.2, 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6144351",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(errRate)\n",
    "sigma = np.var(errRate, ddof = 1) # 修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29038cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07818181818181819"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9747cad7",
   "metadata": {},
   "source": [
    "> $H_0: \\epsilon=0.08$\n",
    ">\n",
    "> $\\alpha = 0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc1d60",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t = \\frac{\\sqrt{k}(\\mu -\\epsilon_0)}{\\sigma}\n",
    "$$\n",
    "服从自由度为$k-1$的$t$分布\n",
    "![](https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/427a4d0c7f7fdb96f41962d7289fe29.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "815df8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.08\n",
    "k = len(y_pred)\n",
    "t = np.sqrt(k)*(mu - epsilon)/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64c6654d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8301922258198599"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf624e6",
   "metadata": {},
   "source": [
    "> 以90%的置信度认为模型的泛化错误率等于8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1201a20",
   "metadata": {},
   "source": [
    "### 4.3. 交叉验证t检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef81fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15c0c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBC = NaiveBayesClassifierContinuous()\n",
    "errRateD = []; errRateC = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "    y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "    errCount_D = 0; errCount_C = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred_D[i] != y_test[i]:\n",
    "            errCount_D += 1\n",
    "        if y_pred_C[i] != y_test[i]:\n",
    "            errCount_C += 1\n",
    "    errRateD.append(errCount_D/len(y_pred))\n",
    "    errRateC.append(errCount_C/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ae621",
   "metadata": {},
   "source": [
    "> $H_0$: 两模型性能相当\n",
    ">\n",
    "> $\\alpha=0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3b9c5",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t=|\\frac{\\sqrt{k}\\mu}{\\sigma}|\n",
    "$$\n",
    "临界值$t_{\\alpha/2,k-1}=2.262$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09e14bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "errRateDelta = np.array(errRateD) - np.array(errRateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2971173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(y_pred)\n",
    "mu = errRateDelta.mean()\n",
    "sigma = errRateDelta.var(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b3fb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.abs(np.sqrt(k)*mu/sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dba404a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.14031611621005"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444562c1",
   "metadata": {},
   "source": [
    "> $t>2.262$ 拒绝原假设"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "710d2f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errRateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e2f125c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errRateD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149d1d9",
   "metadata": {},
   "source": [
    "> 两学习器有显著的差别 \n",
    ">\n",
    "> 离散型平均错误率较小，认为其性能较优"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e4764",
   "metadata": {},
   "source": [
    "**采用$5\\times 2$折交叉验证**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ad6bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBC = NaiveBayesClassifierContinuous()\n",
    "errRateDD = []; errRateCC = []\n",
    "for i in range(5):\n",
    "    errRateD = []; errRateC = []\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=i) # 五次随机\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "        NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "        y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "        errCount_D = 0; errCount_C = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_pred_D[i] != y_test[i]:\n",
    "                errCount_D += 1\n",
    "            if y_pred_C[i] != y_test[i]:\n",
    "                errCount_C += 1\n",
    "        errRateD.append(errCount_D/len(y_pred))\n",
    "        errRateC.append(errCount_C/len(y_pred))\n",
    "    errRateDD.append(errRateD); errRateCC.append(errRateC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56275d",
   "metadata": {},
   "source": [
    "为了缓解测试错误率的非独立性，仅计算第一次的2折交叉验证的平均值$\\mu$，和每次的方差\n",
    "$$\n",
    "μ=0.5×(Δ_𝑖^1+Δ_𝑖^2 )\\\\\n",
    "σ_𝑖^2=(Δ_𝑖^1−\\frac{Δ_𝑖^1+Δ_𝑖^2}{2})^2+(Δ_𝑖^1−\\frac{Δ_𝑖^2+Δ_𝑖^2}{2})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42ec270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "errRateDelta = np.array(errRateCC) - np.array(errRateDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcd0f1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.2],\n",
       "       [1.2, 0.4],\n",
       "       [0.8, 0.6],\n",
       "       [0.5, 0. ],\n",
       "       [0.5, 0.1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRateDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56798806",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(errRateDelta[0])\n",
    "sigma = np.var(errRateDelta, axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b06bd",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t=\\frac{\\mu}{\\sqrt{0.2\\sum_{i=1}^{5}\\sigma_i^2}}\n",
    "$$\n",
    "服从自由度为5的$t$分布，临界值$t_{\\alpha/2,5}$\n",
    "\n",
    "$\\alpha=0.1$时，$t_{\\alpha/2,5}=2.776$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28d39b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mu/np.sqrt(0.2*sum(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14abcb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0188893920442685"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c6a81",
   "metadata": {},
   "source": [
    "> 小于临界值，认为两学习器没有显著差别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c47375",
   "metadata": {},
   "source": [
    "### 4.4. McNemar检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d38c6e",
   "metadata": {},
   "source": [
    "**列联表**\n",
    "![](https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/20221214214255.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7576afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "y_train, y_test = y.values[train_index], y.values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "075c637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete() # 学习器A\n",
    "NBC = NaiveBayesClassifierContinuous()# 学习器B\n",
    "errCount_D = 0; errCount_C = 0\n",
    "\n",
    "NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "conTable = np.zeros([2,2])\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_D[i] == 1:\n",
    "        if y_pred_C[i] == 1:\n",
    "            conTable[0][0] += 1\n",
    "        else:\n",
    "            conTable[1][0] += 1\n",
    "    else:\n",
    "        if y_pred_C[i] == 1:\n",
    "            conTable[0][1] += 1\n",
    "        else:\n",
    "            conTable[1][1] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c24ab5",
   "metadata": {},
   "source": [
    "> $H_0: e_{01}=e_{10}$\n",
    "$$\n",
    "τ_{χ^2 }=\\frac{(𝑏−𝑐)^2}{𝑏+𝑐}\n",
    "$$\n",
    "服从自由度为1的卡方分布\n",
    ">\n",
    "> $\\alpha =0.05$时，临界值为3.8415\n",
    ">\n",
    "> $\\alpha =0.1$时，临界值为2.7055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6839a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chis = (conTable[0][1] - conTable[1][0])**2/(conTable[0][1] + conTable[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63dee750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9b40a",
   "metadata": {},
   "source": [
    "> 小于临界值，以95%的置信度认为，两学习器的性能没有显著差别"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c55e9d796d921fb146b10323731b2f7df76c41c7c7d9d40465948f697d4aaa4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
