{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e25ebee",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "**结论**\n",
    "\n",
    "1. 实现了基于离散属性和连续属性的朴素贝叶斯分类器\n",
    "2. 进行了二项检验、t检验、交叉验证t检验、McNemar检验，得出以下结论：\n",
    "    1. 通过二项检验发现，对于离散属性的朴素贝叶斯分类器，在**99%的置信水平**下，认为模型分**泛化错误率小于42%**\n",
    "    2. 通过t检验发现，对于离散属性的朴素贝叶斯分类器，在以**90%的置信度**下，认为模型的**泛化错误率等于8%**\n",
    "    3. 通过交叉验证t检验发现，离散属性的朴素贝叶斯分类器的性能比连续属性的更优（**未考虑到独立采样**）\n",
    "    4. 通过$5\\times 2$折交叉验证t检验发现，两者性能**没有显著差别**\n",
    "    5. 通过McNemar检验发现，两者性能**没有显著差别**\n",
    "    \n",
    "\n",
    "**数据**\n",
    "\n",
    "    - 2021冬模式识别数据收集.xlsx\n",
    "   \n",
    "> 说明:\n",
    ">\n",
    "> 以身高、体重、脚长、尺码来判断性别\n",
    ">\n",
    "> 以上特征可以视为离散型属性，亦可以视为连续型属性\n",
    " \n",
    " **优点**：小样本，多分类\n",
    "\n",
    "**缺点**：对于输入数据敏感\n",
    "\n",
    "**公式**\n",
    "\n",
    "$$\n",
    "P(c|x)=\\frac{p(c,x)}{p(x)}=\\frac{P(c)p(x|c)}{p(x)}=\\frac{P(c)}{p(x)}\\prod_{i=1}^{d}{P(x_i|c)}\n",
    "$$\n",
    "\n",
    "对于所有类别来说，$P(x)$一样，因此只考虑分子部分\n",
    "\n",
    "$$\n",
    "h_{nb}=arg\\ max_{c\\in \\gamma}P(c)\\prod_{i=1}^d{P(x_i|c)}\n",
    "$$\n",
    "\n",
    "1. 离散\n",
    "$$\n",
    "p(c)=\\frac{|D_c|}{|D|}\n",
    "$$\n",
    "\n",
    "> 拉普拉斯修正 $p(c)=\\frac{|D_c|+1}{|D|+N}$\n",
    "\n",
    "\n",
    "2. 连续\n",
    "\n",
    "> 假设$p(x_i|c)\\sim N(\\mu_{c,i},\\sigma_{c,i}^2)$\n",
    "\n",
    "$$\n",
    "p(x_i|c)=\\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}} exp(-\\frac{(x_i-\\mu_{c,i})^2}{2\\sigma_{c,i}^2})\n",
    "$$\n",
    " \n",
    " **环境**\n",
    " \n",
    " ```shell\n",
    " Python                         3.8.4\n",
    " matplotlib                     3.5.2\n",
    " numpy                          1.22.4\n",
    " pandas                         1.3.5\n",
    " scikit-learn                   1.1.1\n",
    " seaborn                        0.11.2\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8da53",
   "metadata": {},
   "source": [
    "## 1. 导入包和模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b294c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from collections import Counter\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e176ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fileName):\n",
    "    data = pd.read_excel(fileName,index_col=0)\n",
    "    data = data.dropna(axis=1)\n",
    "    data['性别'] = data['性别'].map({'男':0,'女':1})\n",
    "    # sns.pairplot(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1090abc",
   "metadata": {},
   "source": [
    "## 2. 离散属性的朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab7e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义朴素贝叶斯分类器-离散型\n",
    "class NaiveBayesClassifierDiscrete:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.prior_prob = None\n",
    "        self.conditional_prob = None\n",
    "        self.num_values = None\n",
    "\n",
    "    # 训练函数\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 计算先验概率和条件概率        \n",
    "        parameters:\n",
    "            - data 训练特征矩阵\n",
    "            - labels 训练标签向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        # 计算先验概率\n",
    "        label_counts = Counter(labels)  # 计算每个标签的数量\n",
    "        num_samples = len(labels)  # 计算样本总数\n",
    "        self.prior_prob = {label: count / num_samples for label, count in label_counts.items()}  # 计算每个标签的先验概率\n",
    "\n",
    "        # 计算条件概率\n",
    "        self.conditional_prob = {}\n",
    "        self.num_values = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.conditional_prob[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                self.conditional_prob[label][feature_index] = {}\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                value_counts = Counter(feature_values)  # 统计每个特征值出现的次数\n",
    "                self.num_values[feature_index] = len(feature_values)  # 该特征值出现的总次数\n",
    "                # self.conditional_prob[label][feature_index] = {value: count / num_values for value, count in value_counts.items()}  # 计算每个特征值的条件概率\n",
    "                # 拉普拉斯变换修正\n",
    "                self.conditional_prob[label][feature_index] = {value: (count+1) / (2 * self.num_values[feature_index]) for value, count in value_counts.items()}  # 计算每个特征值的条件概率\n",
    "        \n",
    "\n",
    "    # 预测函数\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 给定特征值，预测类别\n",
    "        parameters:\n",
    "            - data 测试特征向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        for sample in data:\n",
    "            # 计算每个标签的概率\n",
    "            label_prob = {label: self.prior_prob[label] for label in self.prior_prob.keys()}\n",
    "            for label in self.prior_prob.keys():\n",
    "                for feature_index in range(len(sample)):\n",
    "                    feature_value = sample[feature_index]\n",
    "                    if feature_value in self.conditional_prob[label][feature_index].keys():\n",
    "                        label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    else:\n",
    "                        # label_prob[label] = 0\n",
    "                        # 拉普拉斯修正\n",
    "                        label_prob[label] *= 1 / (2*self.num_values[feature_index])\n",
    "            # 根据概率选择最大的标签\n",
    "            labels.append(max(label_prob, key=label_prob.get))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99761bc3",
   "metadata": {},
   "source": [
    "## 3. 连续属性的朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae43db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义朴素贝叶斯分类器-连续型\n",
    "class NaiveBayesClassifierContinuous:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.prior_prob = None\n",
    "        self.conditional_prob = None\n",
    "        self.num_values = None\n",
    "        self.mu = None\n",
    "        self.std = None\n",
    "    \n",
    "    def gauss(self, x, mu, std):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 计算高斯函数值\n",
    "        parameters:\n",
    "            - mu 均值\n",
    "            - std 标准差\n",
    "        return:\n",
    "            - ans 函数值\n",
    "        \"\"\"\n",
    "        ans = 1/(np.sqrt(2*np.pi)*std)*np.exp(-(x-mu)**2/(2*(std**2)))\n",
    "        return ans\n",
    "\n",
    "    # 训练函数\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 计算先验概率和条件概率        \n",
    "        parameters:\n",
    "            - data 训练特征矩阵\n",
    "            - labels 训练标签向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        # 计算先验概率\n",
    "        label_counts = Counter(labels)  # 计算每个标签的数量\n",
    "        num_samples = len(labels)  # 计算样本总数\n",
    "        self.prior_prob = {label: count / num_samples for label, count in label_counts.items()}  # 计算每个标签的先验概率\n",
    "        \n",
    "        # 计算每个标签的第i个特征的均值mu和标准差std\n",
    "        # 用样本均值和标准差来进行估计\n",
    "        self.mu = {}; self.std = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.mu[label] = {}; self.std[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                mu = np.mean(feature_values); std = np.std(feature_values)\n",
    "                self.mu[label][feature_index] = mu\n",
    "                self.std[label][feature_index] = std\n",
    "        \n",
    "    \n",
    "        # 计算条件概率\n",
    "        self.conditional_prob = {}\n",
    "        self.num_values = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.conditional_prob[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                self.num_values[feature_index] = len(feature_values)\n",
    "                value_counts = Counter(feature_values)\n",
    "                self.conditional_prob[label][feature_index] = {value: self.gauss(value, self.mu[label][feature_index], self.std[label][feature_index]) for value in value_counts.keys()}\n",
    "        return self\n",
    "    # 预测函数\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 给定特征值，预测类别\n",
    "        parameters:\n",
    "            - data 测试特征向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        for sample in data:\n",
    "            # 计算每个标签的概率\n",
    "            label_prob = {label: self.prior_prob[label] for label in self.prior_prob.keys()}\n",
    "            for label in self.prior_prob.keys():\n",
    "                for feature_index in range(len(sample)):\n",
    "                    feature_value = sample[feature_index]\n",
    "                    # label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    if feature_value in self.conditional_prob[label][feature_index].keys():\n",
    "                        label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    else:\n",
    "                        # label_prob[label] = 0\n",
    "                        # 拉普拉斯修正\n",
    "                        label_prob[label] *= 1 / (2*self.num_values[feature_index])\n",
    "            # 根据概率选择最大的标签\n",
    "            labels.append(max(label_prob, key=label_prob.get))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53ced5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_C:\t [0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
      "y_pred_D:\t [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
      "y_test:\t\t [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    fileName = './work/2021冬模式识别数据收集.xlsx'\n",
    "    data = load_data(fileName)\n",
    "    X = data.iloc[:, 1:]\n",
    "    y = data.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=8)\n",
    "    X_train = X_train.values; X_test = X_test.values\n",
    "    y_train = y_train.values; y_test = y_test.values\n",
    "    NBC = NaiveBayesClassifierContinuous()\n",
    "    NBD = NaiveBayesClassifierDiscrete()\n",
    "    NBC.data = X_train; NBC.labels = y_train\n",
    "    NBD.data = X_train; NBD.labels = y_train\n",
    "    NBC.fit(X_train, y_train); NBD.fit(X_train, y_train)\n",
    "    y_pred_C = NBC.predict(X_test)\n",
    "    y_pred_D = NBD.predict(X_test)\n",
    "    print('y_pred_C:\\t', y_pred_C)\n",
    "    print('y_pred_D:\\t', y_pred_D)\n",
    "    print('y_test:\\t\\t', list(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7023e",
   "metadata": {},
   "source": [
    "## 4. 比较检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572e02f",
   "metadata": {},
   "source": [
    "### 4.1. 二项检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbfae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456f63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values; X_test = X_test.values\n",
    "y_train = y_train.values; y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258fab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBD.fit(X_train, y_train)\n",
    "y_pred = NBD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a61c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "errCount = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        errCount += 1\n",
    "errRate = errCount/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a384c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09090909090909091"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c690b",
   "metadata": {},
   "source": [
    "> 假设模型的泛化错误率小于42%，\n",
    ">\n",
    "> 即$H_0: \\epsilon < 0.42$\n",
    ">\n",
    "$$\n",
    "P(\\hat{\\epsilon};\\epsilon)=C_{m}^n \\epsilon^m(1-\\epsilon)^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d197d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c37fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b24bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "epsilon = 0.42\n",
    "for n in range(m+1):\n",
    "    p = math.comb(m, n)*(epsilon**m)*((1-epsilon)**n)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f563bd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010989303071931383"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "130a2d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(list(range(m+1)),P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dfb858",
   "metadata": {},
   "source": [
    "> 显著性水平$1-\\alpha = 0.99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cac205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7924626856583731e-07\n",
      "3.578744465504131e-06\n",
      "3.288476340462735e-05\n",
      "0.00018446761998629912\n",
      "0.0007071671254403396\n",
      "0.0019688555868811273\n",
      "0.004144180520399726\n",
      "0.006823152113402926\n",
      "0.00913261038323327\n",
      "0.01045988525095186\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "acc = 0\n",
    "for i in reversed(list(range(m+1))):\n",
    "    acc += P[i]\n",
    "    print(acc)\n",
    "    if acc > alpha:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cdedfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc25d3",
   "metadata": {},
   "source": [
    "> 落在置信区间内\n",
    ">\n",
    "> 以99%的置信水平认为，模型分泛化错误率小于42%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a5504",
   "metadata": {},
   "source": [
    "### 4.2. t检验 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e90b547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "691fcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "errRate = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    NBD.fit(X_train, y_train)\n",
    "    y_pred = NBD.predict(X_test)\n",
    "    errCount = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred[i] != y_test[i]:\n",
    "            errCount += 1\n",
    "    errRate.append(errCount/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75b11dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09090909090909091, 0.0, 0.1, 0.2, 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6144351",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(errRate)\n",
    "sigma = np.var(errRate, ddof = 1) # 修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29038cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07818181818181819"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9747cad7",
   "metadata": {},
   "source": [
    "> $H_0: \\epsilon=0.08$\n",
    ">\n",
    "> $\\alpha = 0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc1d60",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t = \\frac{\\sqrt{k}(\\mu -\\epsilon_0)}{\\sigma}\n",
    "$$\n",
    "服从自由度为$k-1$的$t$分布\n",
    "![](https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/427a4d0c7f7fdb96f41962d7289fe29.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "815df8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.08\n",
    "k = len(y_pred)\n",
    "t = np.sqrt(k)*(mu - epsilon)/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64c6654d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8301922258198599"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf624e6",
   "metadata": {},
   "source": [
    "> 以90%的置信度认为模型的泛化错误率等于8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1201a20",
   "metadata": {},
   "source": [
    "### 4.3. 交叉验证t检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef81fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15c0c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBC = NaiveBayesClassifierContinuous()\n",
    "errRateD = []; errRateC = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "    y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "    errCount_D = 0; errCount_C = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred_D[i] != y_test[i]:\n",
    "            errCount_D += 1\n",
    "        if y_pred_C[i] != y_test[i]:\n",
    "            errCount_C += 1\n",
    "    errRateD.append(errCount_D/len(y_pred))\n",
    "    errRateC.append(errCount_C/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ae621",
   "metadata": {},
   "source": [
    "> $H_0$: 两模型性能相当\n",
    ">\n",
    "> $\\alpha=0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3b9c5",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t=|\\frac{\\sqrt{k}\\mu}{\\sigma}|\n",
    "$$\n",
    "临界值$t_{\\alpha/2,k-1}=2.262$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09e14bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "errRateDelta = np.array(errRateD) - np.array(errRateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2971173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(y_pred)\n",
    "mu = errRateDelta.mean()\n",
    "sigma = errRateDelta.var(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b3fb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.abs(np.sqrt(k)*mu/sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dba404a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.14031611621005"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444562c1",
   "metadata": {},
   "source": [
    "> $t>2.262$ 拒绝原假设"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "710d2f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errRateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e2f125c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errRateD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149d1d9",
   "metadata": {},
   "source": [
    "> 两学习器有显著的差别 \n",
    ">\n",
    "> 离散型平均错误率较小，认为其性能较优"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e4764",
   "metadata": {},
   "source": [
    "**采用$5\\times 2$折交叉验证**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ad6bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBC = NaiveBayesClassifierContinuous()\n",
    "errRateDD = []; errRateCC = []\n",
    "for i in range(5):\n",
    "    errRateD = []; errRateC = []\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=i) # 五次随机\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "        NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "        y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "        errCount_D = 0; errCount_C = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_pred_D[i] != y_test[i]:\n",
    "                errCount_D += 1\n",
    "            if y_pred_C[i] != y_test[i]:\n",
    "                errCount_C += 1\n",
    "        errRateD.append(errCount_D/len(y_pred))\n",
    "        errRateC.append(errCount_C/len(y_pred))\n",
    "    errRateDD.append(errRateD); errRateCC.append(errRateC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc56275d",
   "metadata": {},
   "source": [
    "为了缓解测试错误率的非独立性，仅计算第一次的2折交叉验证的平均值$\\mu$，和每次的方差\n",
    "$$\n",
    "μ=0.5×(Δ_𝑖^1+Δ_𝑖^2 )\\\\\n",
    "σ_𝑖^2=(Δ_𝑖^1−\\frac{Δ_𝑖^1+Δ_𝑖^2}{2})^2+(Δ_𝑖^1−\\frac{Δ_𝑖^2+Δ_𝑖^2}{2})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42ec270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "errRateDelta = np.array(errRateCC) - np.array(errRateDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcd0f1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.2],\n",
       "       [1.2, 0.4],\n",
       "       [0.8, 0.6],\n",
       "       [0.5, 0. ],\n",
       "       [0.5, 0.1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRateDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56798806",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(errRateDelta[0])\n",
    "sigma = np.var(errRateDelta, axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b06bd",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t=\\frac{\\mu}{\\sqrt{0.2\\sum_{i=1}^{5}\\sigma_i^2}}\n",
    "$$\n",
    "服从自由度为5的$t$分布，临界值$t_{\\alpha/2,5}$\n",
    "\n",
    "$\\alpha=0.1$时，$t_{\\alpha/2,5}=2.776$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28d39b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mu/np.sqrt(0.2*sum(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14abcb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0188893920442685"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c6a81",
   "metadata": {},
   "source": [
    "> 小于临界值，认为两学习器没有显著差别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c47375",
   "metadata": {},
   "source": [
    "### 4.4. McNemar检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d38c6e",
   "metadata": {},
   "source": [
    "**列联表**\n",
    "![](https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/20221214214255.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7576afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "y_train, y_test = y.values[train_index], y.values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "075c637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete() # 学习器A\n",
    "NBC = NaiveBayesClassifierContinuous()# 学习器B\n",
    "errCount_D = 0; errCount_C = 0\n",
    "\n",
    "NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "conTable = np.zeros([2,2])\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_D[i] == 1:\n",
    "        if y_pred_C[i] == 1:\n",
    "            conTable[0][0] += 1\n",
    "        else:\n",
    "            conTable[1][0] += 1\n",
    "    else:\n",
    "        if y_pred_C[i] == 1:\n",
    "            conTable[0][1] += 1\n",
    "        else:\n",
    "            conTable[1][1] += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8c24ab5",
   "metadata": {},
   "source": [
    "> $H_0: e_{01}=e_{10}$\n",
    "$$\n",
    "τ_{χ^2 }=\\frac{(𝑏−𝑐)^2}{𝑏+𝑐}\n",
    "$$\n",
    "服从自由度为1的卡方分布\n",
    ">\n",
    "> $\\alpha =0.05$时，临界值为3.8415\n",
    ">\n",
    "> $\\alpha =0.1$时，临界值为2.7055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6839a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chis = (conTable[0][1] - conTable[1][0])**2/(conTable[0][1] + conTable[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63dee750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9b40a",
   "metadata": {},
   "source": [
    "> 小于临界值，以95%的置信度认为，两学习器的性能没有显著差别"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
