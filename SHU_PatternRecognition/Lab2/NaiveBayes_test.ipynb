{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76998b06",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "**结论**\n",
    "\n",
    "1. 实现了基于离散属性和连续属性的朴素贝叶斯分类器\n",
    "2. 进行了二项检验、t检验、交叉验证t检验、McNemar检验，得出以下结论：\n",
    "    1. 通过二项检验发现，对于离散属性的朴素贝叶斯分类器，在**99%的置信水平**下，认为模型分**泛化错误率小于42%**\n",
    "    2. 通过t检验发现，对于离散属性的朴素贝叶斯分类器，在以**90%的置信度**下，认为模型的**泛化错误率等于8%**\n",
    "    3. 通过交叉验证t检验发现，离散属性的朴素贝叶斯分类器的性能比连续属性的更优（**未考虑到独立采样**）\n",
    "    4. 通过$5\\times 2$折交叉验证t检验发现，两者性能**没有显著差别**\n",
    "    5. 通过McNemar检验发现，两者性能**没有显著差别**\n",
    "    \n",
    "\n",
    "**数据**\n",
    "\n",
    "    - 2021冬模式识别数据收集.xlsx\n",
    "   \n",
    "> 说明:\n",
    ">\n",
    "> 以身高、体重、脚长、尺码来判断性别\n",
    ">\n",
    "> 以上特征可以视为离散型属性，亦可以视为连续型属性\n",
    " \n",
    " **优点**：小样本，多分类\n",
    "\n",
    "**缺点**：对于输入数据敏感\n",
    "\n",
    "**公式**\n",
    "\n",
    "$$\n",
    "P(c|x)=\\frac{p(c,x)}{p(x)}=\\frac{P(c)p(x|c)}{p(x)}=\\frac{P(c)}{p(x)}\\prod_{i=1}^{d}{P(x_i|c)}\n",
    "$$\n",
    "\n",
    "对于所有类别来说，$P(x)$一样，因此只考虑分子部分\n",
    "\n",
    "$$\n",
    "h_{nb}=arg\\ max_{c\\in \\gamma}P(c)\\prod_{i=1}^d{P(x_i|c)}\n",
    "$$\n",
    "\n",
    "1. 离散\n",
    "$$\n",
    "p(c)=\\frac{|D_c|}{|D|}\n",
    "$$\n",
    "\n",
    "> 拉普拉斯修正 $p(c)=\\frac{|D_c|+1}{|D|+N}$\n",
    "\n",
    "\n",
    "2. 连续\n",
    "\n",
    "> 假设$p(x_i|c)\\sim N(\\mu_{c,i},\\sigma_{c,i}^2)$\n",
    "\n",
    "$$\n",
    "p(x_i|c)=\\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}} exp(-\\frac{(x_i-\\mu_{c,i})^2}{2\\sigma_{c,i}^2})\n",
    "$$\n",
    " \n",
    " **环境**\n",
    " \n",
    " ```shell\n",
    " Python                         3.8.4\n",
    " matplotlib                     3.5.2\n",
    " numpy                          1.22.4\n",
    " pandas                         1.3.5\n",
    " scikit-learn                   1.1.1\n",
    " seaborn                        0.11.2\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478d3c0",
   "metadata": {},
   "source": [
    "## 1. 导入包和模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1384c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from collections import Counter\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd116c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fileName):\n",
    "    data = pd.read_excel(fileName,index_col=0)\n",
    "    data = data.dropna(axis=1)\n",
    "    data['性别'] = data['性别'].map({'男':0,'女':1})\n",
    "    # sns.pairplot(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825fd6bf",
   "metadata": {},
   "source": [
    "## 2. 离散属性的朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dde1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义朴素贝叶斯分类器-离散型\n",
    "class NaiveBayesClassifierDiscrete:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.prior_prob = None\n",
    "        self.conditional_prob = None\n",
    "        self.num_values = None\n",
    "\n",
    "    # 训练函数\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 计算先验概率和条件概率        \n",
    "        parameters:\n",
    "            - data 训练特征矩阵\n",
    "            - labels 训练标签向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        # 计算先验概率\n",
    "        label_counts = Counter(labels)  # 计算每个标签的数量\n",
    "        num_samples = len(labels)  # 计算样本总数\n",
    "        self.prior_prob = {label: count / num_samples for label, count in label_counts.items()}  # 计算每个标签的先验概率\n",
    "\n",
    "        # 计算条件概率\n",
    "        self.conditional_prob = {}\n",
    "        self.num_values = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.conditional_prob[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                self.conditional_prob[label][feature_index] = {}\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                value_counts = Counter(feature_values)  # 统计每个特征值出现的次数\n",
    "                self.num_values[feature_index] = len(feature_values)  # 该特征值出现的总次数\n",
    "                # self.conditional_prob[label][feature_index] = {value: count / num_values for value, count in value_counts.items()}  # 计算每个特征值的条件概率\n",
    "                # 拉普拉斯变换修正\n",
    "                self.conditional_prob[label][feature_index] = {value: (count+1) / (2 * self.num_values[feature_index]) for value, count in value_counts.items()}  # 计算每个特征值的条件概率\n",
    "        \n",
    "\n",
    "    # 预测函数\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 给定特征值，预测类别\n",
    "        parameters:\n",
    "            - data 测试特征向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        for sample in data:\n",
    "            # 计算每个标签的概率\n",
    "            label_prob = {label: self.prior_prob[label] for label in self.prior_prob.keys()}\n",
    "            for label in self.prior_prob.keys():\n",
    "                for feature_index in range(len(sample)):\n",
    "                    feature_value = sample[feature_index]\n",
    "                    if feature_value in self.conditional_prob[label][feature_index].keys():\n",
    "                        label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    else:\n",
    "                        # label_prob[label] = 0\n",
    "                        # 拉普拉斯修正\n",
    "                        label_prob[label] *= 1 / (2*self.num_values[feature_index])\n",
    "            # 根据概率选择最大的标签\n",
    "            labels.append(max(label_prob, key=label_prob.get))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d98974",
   "metadata": {},
   "source": [
    "## 3. 连续属性的朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504289f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义朴素贝叶斯分类器-连续型\n",
    "class NaiveBayesClassifierContinuous:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.prior_prob = None\n",
    "        self.conditional_prob = None\n",
    "        self.num_values = None\n",
    "        self.mu = None\n",
    "        self.std = None\n",
    "    \n",
    "    def gauss(self, x, mu, std):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 计算高斯函数值\n",
    "        parameters:\n",
    "            - mu 均值\n",
    "            - std 标准差\n",
    "        return:\n",
    "            - ans 函数值\n",
    "        \"\"\"\n",
    "        ans = 1/(np.sqrt(2*np.pi)*std)*np.exp(-(x-mu)**2/(2*(std**2)))\n",
    "        return ans\n",
    "\n",
    "    # 训练函数\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 计算先验概率和条件概率        \n",
    "        parameters:\n",
    "            - data 训练特征矩阵\n",
    "            - labels 训练标签向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        # 计算先验概率\n",
    "        label_counts = Counter(labels)  # 计算每个标签的数量\n",
    "        num_samples = len(labels)  # 计算样本总数\n",
    "        self.prior_prob = {label: count / num_samples for label, count in label_counts.items()}  # 计算每个标签的先验概率\n",
    "        \n",
    "        # 计算每个标签的第i个特征的均值mu和标准差std\n",
    "        # 用样本均值和标准差来进行估计\n",
    "        self.mu = {}; self.std = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.mu[label] = {}; self.std[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                mu = np.mean(feature_values); std = np.std(feature_values)\n",
    "                self.mu[label][feature_index] = mu\n",
    "                self.std[label][feature_index] = std\n",
    "        \n",
    "    \n",
    "        # 计算条件概率\n",
    "        self.conditional_prob = {}\n",
    "        self.num_values = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.conditional_prob[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                self.num_values[feature_index] = len(feature_values)\n",
    "                value_counts = Counter(feature_values)\n",
    "                self.conditional_prob[label][feature_index] = {value: self.gauss(value, self.mu[label][feature_index], self.std[label][feature_index]) for value in value_counts.keys()}\n",
    "        return self\n",
    "    # 预测函数\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        函数说明:\n",
    "            - 给定特征值，预测类别\n",
    "        parameters:\n",
    "            - data 测试特征向量\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        for sample in data:\n",
    "            # 计算每个标签的概率\n",
    "            label_prob = {label: self.prior_prob[label] for label in self.prior_prob.keys()}\n",
    "            for label in self.prior_prob.keys():\n",
    "                for feature_index in range(len(sample)):\n",
    "                    feature_value = sample[feature_index]\n",
    "                    # label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    if feature_value in self.conditional_prob[label][feature_index].keys():\n",
    "                        label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    else:\n",
    "                        # label_prob[label] = 0\n",
    "                        # 拉普拉斯修正\n",
    "                        label_prob[label] *= 1 / (2*self.num_values[feature_index])\n",
    "            # 根据概率选择最大的标签\n",
    "            labels.append(max(label_prob, key=label_prob.get))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0a3bae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_C:\t [0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
      "y_pred_D:\t [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
      "y_test:\t\t [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    fileName = './work/2021冬模式识别数据收集.xlsx'\n",
    "    data = load_data(fileName)\n",
    "    X = data.iloc[:, 1:]\n",
    "    y = data.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=8)\n",
    "    X_train = X_train.values; X_test = X_test.values\n",
    "    y_train = y_train.values; y_test = y_test.values\n",
    "    NBC = NaiveBayesClassifierContinuous()\n",
    "    NBD = NaiveBayesClassifierDiscrete()\n",
    "    NBC.data = X_train; NBC.labels = y_train\n",
    "    NBD.data = X_train; NBD.labels = y_train\n",
    "    NBC.fit(X_train, y_train); NBD.fit(X_train, y_train)\n",
    "    y_pred_C = NBC.predict(X_test)\n",
    "    y_pred_D = NBD.predict(X_test)\n",
    "    print('y_pred_C:\\t', y_pred_C)\n",
    "    print('y_pred_D:\\t', y_pred_D)\n",
    "    print('y_test:\\t\\t', list(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02904be2",
   "metadata": {},
   "source": [
    "## 4. 比较检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d28084e",
   "metadata": {},
   "source": [
    "### 4.1. 二项检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14117402",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47a489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values; X_test = X_test.values\n",
    "y_train = y_train.values; y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2f911b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBD.fit(X_train, y_train)\n",
    "y_pred = NBD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d4124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errCount = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        errCount += 1\n",
    "errRate = errCount/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b69d87ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.09090909090909091"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b673ff6",
   "metadata": {},
   "source": [
    "> 假设模型的泛化错误率小于42%，\n",
    ">\n",
    "> 即$H_0: \\epsilon < 0.42$\n",
    ">\n",
    "$$\n",
    "P(\\hat{\\epsilon};\\epsilon)=C_{m}^n \\epsilon^m(1-\\epsilon)^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee6533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b91854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbbcd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "epsilon = 0.42\n",
    "for n in range(m+1):\n",
    "    p = math.comb(m, n)*(epsilon**m)*((1-epsilon)**n)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a7174d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.010989303071931383"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b31bf457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(list(range(m+1)),P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a43646",
   "metadata": {},
   "source": [
    "> 显著性水平$1-\\alpha = 0.99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bb97dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7924626856583731e-07\n",
      "3.578744465504131e-06\n",
      "3.288476340462735e-05\n",
      "0.00018446761998629912\n",
      "0.0007071671254403396\n",
      "0.0019688555868811273\n",
      "0.004144180520399726\n",
      "0.006823152113402926\n",
      "0.00913261038323327\n",
      "0.01045988525095186\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "acc = 0\n",
    "for i in reversed(list(range(m+1))):\n",
    "    acc += P[i]\n",
    "    print(acc)\n",
    "    if acc > alpha:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96dde5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad361b",
   "metadata": {},
   "source": [
    "> 落在置信区间内\n",
    ">\n",
    "> 以99%的置信水平认为，模型分泛化错误率小于42%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c308e",
   "metadata": {},
   "source": [
    "### 4.2. t检验 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76bc3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "433bfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "errRate = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    NBD.fit(X_train, y_train)\n",
    "    y_pred = NBD.predict(X_test)\n",
    "    errCount = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred[i] != y_test[i]:\n",
    "            errCount += 1\n",
    "    errRate.append(errCount/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed883a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0.09090909090909091, 0.0, 0.1, 0.2, 0.0]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82806c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(errRate)\n",
    "sigma = np.var(errRate, ddof = 1) # 修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b4da23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.07818181818181819"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686d08e8",
   "metadata": {},
   "source": [
    "> $H_0: \\epsilon=0.08$\n",
    ">\n",
    "> $\\alpha = 0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4b73d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t = \\frac{\\sqrt{k}(\\mu -\\epsilon_0)}{\\sigma}\n",
    "$$\n",
    "服从自由度为$k-1$的$t$分布\n",
    "![](https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/427a4d0c7f7fdb96f41962d7289fe29.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ed285b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.08\n",
    "k = len(y_pred)\n",
    "t = np.sqrt(k)*(mu - epsilon)/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6df0a506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-0.8301922258198599"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2bf99",
   "metadata": {},
   "source": [
    "> 以90%的置信度认为模型的泛化错误率等于8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609356a",
   "metadata": {},
   "source": [
    "### 4.3. 交叉验证t检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87eb8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afde0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBC = NaiveBayesClassifierContinuous()\n",
    "errRateD = []; errRateC = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "    y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "    errCount_D = 0; errCount_C = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred_D[i] != y_test[i]:\n",
    "            errCount_D += 1\n",
    "        if y_pred_C[i] != y_test[i]:\n",
    "            errCount_C += 1\n",
    "    errRateD.append(errCount_D/len(y_pred))\n",
    "    errRateC.append(errCount_C/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64038eb",
   "metadata": {},
   "source": [
    "> $H_0$: 两模型性能相当\n",
    ">\n",
    "> $\\alpha=0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4124f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t=|\\frac{\\sqrt{k}\\mu}{\\sigma}|\n",
    "$$\n",
    "临界值$t_{\\alpha/2,k-1}=2.262$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58f7ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "errRateDelta = np.array(errRateD) - np.array(errRateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dedf23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(y_pred)\n",
    "mu = errRateDelta.mean()\n",
    "sigma = errRateDelta.var(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dac24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.abs(np.sqrt(k)*mu/sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b897c9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "36.14031611621005"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd56c6",
   "metadata": {},
   "source": [
    "> $t>2.262$ 拒绝原假设"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90488a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.16"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errRateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23c40f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.08"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errRateD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc0ba6",
   "metadata": {},
   "source": [
    "> 两学习器有显著的差别 \n",
    ">\n",
    "> 离散型平均错误率较小，认为其性能较优"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc4d1fd",
   "metadata": {},
   "source": [
    "**采用$5\\times 2$折交叉验证**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7b3dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBC = NaiveBayesClassifierContinuous()\n",
    "errRateDD = []; errRateCC = []\n",
    "for i in range(5):\n",
    "    errRateD = []; errRateC = []\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=i) # 五次随机\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "        NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "        y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "        errCount_D = 0; errCount_C = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_pred_D[i] != y_test[i]:\n",
    "                errCount_D += 1\n",
    "            if y_pred_C[i] != y_test[i]:\n",
    "                errCount_C += 1\n",
    "        errRateD.append(errCount_D/len(y_pred))\n",
    "        errRateC.append(errCount_C/len(y_pred))\n",
    "    errRateDD.append(errRateD); errRateCC.append(errRateC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1392be0e",
   "metadata": {},
   "source": [
    "为了缓解测试错误率的非独立性，仅计算第一次的2折交叉验证的平均值$\\mu$，和每次的方差\n",
    "$$\n",
    "μ=0.5×(Δ_𝑖^1+Δ_𝑖^2 )\\\\\n",
    "σ_𝑖^2=(Δ_𝑖^1−\\frac{Δ_𝑖^1+Δ_𝑖^2}{2})^2+(Δ_𝑖^1−\\frac{Δ_𝑖^2+Δ_𝑖^2}{2})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4386a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "errRateDelta = np.array(errRateCC) - np.array(errRateDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63d419bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.5, 0.2],\n       [1.2, 0.4],\n       [0.8, 0.6],\n       [0.5, 0. ],\n       [0.5, 0.1]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRateDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "420a5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(errRateDelta[0])\n",
    "sigma = np.var(errRateDelta, axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e18a83",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t=\\frac{\\mu}{\\sqrt{0.2\\sum_{i=1}^{5}\\sigma_i^2}}\n",
    "$$\n",
    "服从自由度为5的$t$分布，临界值$t_{\\alpha/2,5}$\n",
    "\n",
    "$\\alpha=0.1$时，$t_{\\alpha/2,5}=2.776$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25ea03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mu/np.sqrt(0.2*sum(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bc95d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.0188893920442685"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd03ca0",
   "metadata": {},
   "source": [
    "> 小于临界值，认为两学习器没有显著差别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc8e75",
   "metadata": {},
   "source": [
    "### 4.4. McNemar检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabea927",
   "metadata": {},
   "source": [
    "**列联表**\n",
    "![](https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/20221214214255.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "181607f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "y_train, y_test = y.values[train_index], y.values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba318484",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete() # 学习器A\n",
    "NBC = NaiveBayesClassifierContinuous()# 学习器B\n",
    "errCount_D = 0; errCount_C = 0\n",
    "\n",
    "NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "conTable = np.zeros([2,2])\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_D[i] == 1:\n",
    "        if y_pred_C[i] == 1:\n",
    "            conTable[0][0] += 1\n",
    "        else:\n",
    "            conTable[1][0] += 1\n",
    "    else:\n",
    "        if y_pred_C[i] == 1:\n",
    "            conTable[0][1] += 1\n",
    "        else:\n",
    "            conTable[1][1] += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "380f5dd0",
   "metadata": {},
   "source": [
    "> $H_0: e_{01}=e_{10}$\n",
    "$$\n",
    "τ_{χ^2 }=\\frac{(𝑏−𝑐)^2}{𝑏+𝑐}\n",
    "$$\n",
    "服从自由度为1的卡方分布\n",
    ">\n",
    "> $\\alpha =0.05$时，临界值为3.8415\n",
    ">\n",
    "> $\\alpha =0.1$时，临界值为2.7055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b2dc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chis = (conTable[0][1] - conTable[1][0])**2/(conTable[0][1] + conTable[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac995f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79813188",
   "metadata": {},
   "source": [
    "> 小于临界值，以95%的置信度认为，两学习器的性能没有显著差别"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**计算F1-score**\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}$$$$\n",
    "Recall = \\frac{TP}{TP + FN}$$$$\n",
    "F-score = \\frac{2Precision * Recall}{Precision + Recall}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# 计算混淆矩阵各类别频数\n",
    "def get_confusion_matrix(y_true, y_pred, flag = 1):\n",
    "    tn = tp = fn = fp = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            if y_pred[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if y_pred[i] == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    if flag == 1:\n",
    "        return tn ,tp, fn, fp\n",
    "    else:\n",
    "        return tp, tn, fp, fn\n",
    "\n",
    "\n",
    "def get_precision(tp, fp):\n",
    "    if tp == 0:\n",
    "        return 0.0\n",
    "    return float(tp) / float(tp + fp)\n",
    "\n",
    "\n",
    "def get_recall(tp, fn):\n",
    "    if tp == 0:\n",
    "        return 0.0\n",
    "    return float(tp) / float(tp + fn)\n",
    "\n",
    "\n",
    "def get_fscore(tp, fp, fn):\n",
    "    precision = get_precision(tp, fp)\n",
    "    recall = get_recall(tp, fn)\n",
    "    try:\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "    except:\n",
    "        return 0.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征为： 身高 体重 脚长 尺码 \n",
      "\tf1-score\n",
      "0\t0.750000\n",
      "1\t0.333333\n"
     ]
    }
   ],
   "source": [
    "def display_f1score(ch = [1, 2, 3, 4], method = NaiveBayesClassifierDiscrete):\n",
    "    name = ['', '身高', '体重', '脚长', '尺码']\n",
    "    fileName = './work/2021冬模式识别数据收集.xlsx'\n",
    "    data = load_data(fileName)\n",
    "    X = data.iloc[:, ch]\n",
    "    y = data.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=8)\n",
    "    X_train = X_train.values; X_test = X_test.values\n",
    "    y_train = y_train.values; y_test = y_test.values\n",
    "    NBD = method()\n",
    "    NBD.data = X_train; NBD.labels = y_train\n",
    "    NBD.fit(X_train, y_train)\n",
    "    y_pred_D = NBD.predict(X_test)\n",
    "    print('特征为：', end = ' ')\n",
    "    for item in ch:\n",
    "        print(name[item], end=' ')\n",
    "    print()\n",
    "    tn0, tp0, fn0, fp0 = get_confusion_matrix(y_test, y_pred_D, 0)\n",
    "    tn1, tp1, fn1, fp1 = get_confusion_matrix(y_test, y_pred_D, 1)\n",
    "    print('\\tf1-score\\n0\\t%f\\n1\\t%f'%(get_fscore(tp0, fp0, fn0), get_fscore(tp1, fp1, fn1)))\n",
    "\n",
    "# 选择特征和分类器\n",
    "display_f1score([1, 2, 3, 4], NaiveBayesClassifierContinuous)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
