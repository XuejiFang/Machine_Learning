{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76998b06",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "**ç»“è®º**\n",
    "\n",
    "1. å®ç°äº†åŸºäºç¦»æ•£å±æ€§å’Œè¿ç»­å±æ€§çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨\n",
    "2. è¿›è¡Œäº†äºŒé¡¹æ£€éªŒã€tæ£€éªŒã€äº¤å‰éªŒè¯tæ£€éªŒã€McNemaræ£€éªŒï¼Œå¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š\n",
    "    1. é€šè¿‡äºŒé¡¹æ£€éªŒå‘ç°ï¼Œå¯¹äºç¦»æ•£å±æ€§çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œåœ¨**99%çš„ç½®ä¿¡æ°´å¹³**ä¸‹ï¼Œè®¤ä¸ºæ¨¡å‹åˆ†**æ³›åŒ–é”™è¯¯ç‡å°äº42%**\n",
    "    2. é€šè¿‡tæ£€éªŒå‘ç°ï¼Œå¯¹äºç¦»æ•£å±æ€§çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œåœ¨ä»¥**90%çš„ç½®ä¿¡åº¦**ä¸‹ï¼Œè®¤ä¸ºæ¨¡å‹çš„**æ³›åŒ–é”™è¯¯ç‡ç­‰äº8%**\n",
    "    3. é€šè¿‡äº¤å‰éªŒè¯tæ£€éªŒå‘ç°ï¼Œç¦»æ•£å±æ€§çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„æ€§èƒ½æ¯”è¿ç»­å±æ€§çš„æ›´ä¼˜ï¼ˆ**æœªè€ƒè™‘åˆ°ç‹¬ç«‹é‡‡æ ·**ï¼‰\n",
    "    4. é€šè¿‡$5\\times 2$æŠ˜äº¤å‰éªŒè¯tæ£€éªŒå‘ç°ï¼Œä¸¤è€…æ€§èƒ½**æ²¡æœ‰æ˜¾è‘—å·®åˆ«**\n",
    "    5. é€šè¿‡McNemaræ£€éªŒå‘ç°ï¼Œä¸¤è€…æ€§èƒ½**æ²¡æœ‰æ˜¾è‘—å·®åˆ«**\n",
    "    \n",
    "\n",
    "**æ•°æ®**\n",
    "\n",
    "    - 2021å†¬æ¨¡å¼è¯†åˆ«æ•°æ®æ”¶é›†.xlsx\n",
    "   \n",
    "> è¯´æ˜:\n",
    ">\n",
    "> ä»¥èº«é«˜ã€ä½“é‡ã€è„šé•¿ã€å°ºç æ¥åˆ¤æ–­æ€§åˆ«\n",
    ">\n",
    "> ä»¥ä¸Šç‰¹å¾å¯ä»¥è§†ä¸ºç¦»æ•£å‹å±æ€§ï¼Œäº¦å¯ä»¥è§†ä¸ºè¿ç»­å‹å±æ€§\n",
    " \n",
    " **ä¼˜ç‚¹**ï¼šå°æ ·æœ¬ï¼Œå¤šåˆ†ç±»\n",
    "\n",
    "**ç¼ºç‚¹**ï¼šå¯¹äºè¾“å…¥æ•°æ®æ•æ„Ÿ\n",
    "\n",
    "**å…¬å¼**\n",
    "\n",
    "$$\n",
    "P(c|x)=\\frac{p(c,x)}{p(x)}=\\frac{P(c)p(x|c)}{p(x)}=\\frac{P(c)}{p(x)}\\prod_{i=1}^{d}{P(x_i|c)}\n",
    "$$\n",
    "\n",
    "å¯¹äºæ‰€æœ‰ç±»åˆ«æ¥è¯´ï¼Œ$P(x)$ä¸€æ ·ï¼Œå› æ­¤åªè€ƒè™‘åˆ†å­éƒ¨åˆ†\n",
    "\n",
    "$$\n",
    "h_{nb}=arg\\ max_{c\\in \\gamma}P(c)\\prod_{i=1}^d{P(x_i|c)}\n",
    "$$\n",
    "\n",
    "1. ç¦»æ•£\n",
    "$$\n",
    "p(c)=\\frac{|D_c|}{|D|}\n",
    "$$\n",
    "\n",
    "> æ‹‰æ™®æ‹‰æ–¯ä¿®æ­£ $p(c)=\\frac{|D_c|+1}{|D|+N}$\n",
    "\n",
    "\n",
    "2. è¿ç»­\n",
    "\n",
    "> å‡è®¾$p(x_i|c)\\sim N(\\mu_{c,i},\\sigma_{c,i}^2)$\n",
    "\n",
    "$$\n",
    "p(x_i|c)=\\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}} exp(-\\frac{(x_i-\\mu_{c,i})^2}{2\\sigma_{c,i}^2})\n",
    "$$\n",
    " \n",
    " **ç¯å¢ƒ**\n",
    " \n",
    " ```shell\n",
    " Python                         3.8.4\n",
    " matplotlib                     3.5.2\n",
    " numpy                          1.22.4\n",
    " pandas                         1.3.5\n",
    " scikit-learn                   1.1.1\n",
    " seaborn                        0.11.2\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478d3c0",
   "metadata": {},
   "source": [
    "## 1. å¯¼å…¥åŒ…å’Œæ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1384c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from collections import Counter\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False   # è§£å†³ä¿å­˜å›¾åƒæ˜¯è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd116c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fileName):\n",
    "    data = pd.read_excel(fileName,index_col=0)\n",
    "    data = data.dropna(axis=1)\n",
    "    data['æ€§åˆ«'] = data['æ€§åˆ«'].map({'ç”·':0,'å¥³':1})\n",
    "    # sns.pairplot(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825fd6bf",
   "metadata": {},
   "source": [
    "## 2. ç¦»æ•£å±æ€§çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dde1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨-ç¦»æ•£å‹\n",
    "class NaiveBayesClassifierDiscrete:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.prior_prob = None\n",
    "        self.conditional_prob = None\n",
    "        self.num_values = None\n",
    "\n",
    "    # è®­ç»ƒå‡½æ•°\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\"\n",
    "        å‡½æ•°è¯´æ˜:\n",
    "            - è®¡ç®—å…ˆéªŒæ¦‚ç‡å’Œæ¡ä»¶æ¦‚ç‡        \n",
    "        parameters:\n",
    "            - data è®­ç»ƒç‰¹å¾çŸ©é˜µ\n",
    "            - labels è®­ç»ƒæ ‡ç­¾å‘é‡\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        # è®¡ç®—å…ˆéªŒæ¦‚ç‡\n",
    "        label_counts = Counter(labels)  # è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„æ•°é‡\n",
    "        num_samples = len(labels)  # è®¡ç®—æ ·æœ¬æ€»æ•°\n",
    "        self.prior_prob = {label: count / num_samples for label, count in label_counts.items()}  # è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„å…ˆéªŒæ¦‚ç‡\n",
    "\n",
    "        # è®¡ç®—æ¡ä»¶æ¦‚ç‡\n",
    "        self.conditional_prob = {}\n",
    "        self.num_values = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.conditional_prob[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                self.conditional_prob[label][feature_index] = {}\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                value_counts = Counter(feature_values)  # ç»Ÿè®¡æ¯ä¸ªç‰¹å¾å€¼å‡ºç°çš„æ¬¡æ•°\n",
    "                self.num_values[feature_index] = len(feature_values)  # è¯¥ç‰¹å¾å€¼å‡ºç°çš„æ€»æ¬¡æ•°\n",
    "                # self.conditional_prob[label][feature_index] = {value: count / num_values for value, count in value_counts.items()}  # è®¡ç®—æ¯ä¸ªç‰¹å¾å€¼çš„æ¡ä»¶æ¦‚ç‡\n",
    "                # æ‹‰æ™®æ‹‰æ–¯å˜æ¢ä¿®æ­£\n",
    "                self.conditional_prob[label][feature_index] = {value: (count+1) / (2 * self.num_values[feature_index]) for value, count in value_counts.items()}  # è®¡ç®—æ¯ä¸ªç‰¹å¾å€¼çš„æ¡ä»¶æ¦‚ç‡\n",
    "        \n",
    "\n",
    "    # é¢„æµ‹å‡½æ•°\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        å‡½æ•°è¯´æ˜:\n",
    "            - ç»™å®šç‰¹å¾å€¼ï¼Œé¢„æµ‹ç±»åˆ«\n",
    "        parameters:\n",
    "            - data æµ‹è¯•ç‰¹å¾å‘é‡\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        for sample in data:\n",
    "            # è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„æ¦‚ç‡\n",
    "            label_prob = {label: self.prior_prob[label] for label in self.prior_prob.keys()}\n",
    "            for label in self.prior_prob.keys():\n",
    "                for feature_index in range(len(sample)):\n",
    "                    feature_value = sample[feature_index]\n",
    "                    if feature_value in self.conditional_prob[label][feature_index].keys():\n",
    "                        label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    else:\n",
    "                        # label_prob[label] = 0\n",
    "                        # æ‹‰æ™®æ‹‰æ–¯ä¿®æ­£\n",
    "                        label_prob[label] *= 1 / (2*self.num_values[feature_index])\n",
    "            # æ ¹æ®æ¦‚ç‡é€‰æ‹©æœ€å¤§çš„æ ‡ç­¾\n",
    "            labels.append(max(label_prob, key=label_prob.get))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d98974",
   "metadata": {},
   "source": [
    "## 3. è¿ç»­å±æ€§çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504289f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨-è¿ç»­å‹\n",
    "class NaiveBayesClassifierContinuous:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.prior_prob = None\n",
    "        self.conditional_prob = None\n",
    "        self.num_values = None\n",
    "        self.mu = None\n",
    "        self.std = None\n",
    "    \n",
    "    def gauss(self, x, mu, std):\n",
    "        \"\"\"\n",
    "        å‡½æ•°è¯´æ˜:\n",
    "            - è®¡ç®—é«˜æ–¯å‡½æ•°å€¼\n",
    "        parameters:\n",
    "            - mu å‡å€¼\n",
    "            - std æ ‡å‡†å·®\n",
    "        return:\n",
    "            - ans å‡½æ•°å€¼\n",
    "        \"\"\"\n",
    "        ans = 1/(np.sqrt(2*np.pi)*std)*np.exp(-(x-mu)**2/(2*(std**2)))\n",
    "        return ans\n",
    "\n",
    "    # è®­ç»ƒå‡½æ•°\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\"\n",
    "        å‡½æ•°è¯´æ˜:\n",
    "            - è®¡ç®—å…ˆéªŒæ¦‚ç‡å’Œæ¡ä»¶æ¦‚ç‡        \n",
    "        parameters:\n",
    "            - data è®­ç»ƒç‰¹å¾çŸ©é˜µ\n",
    "            - labels è®­ç»ƒæ ‡ç­¾å‘é‡\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        # è®¡ç®—å…ˆéªŒæ¦‚ç‡\n",
    "        label_counts = Counter(labels)  # è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„æ•°é‡\n",
    "        num_samples = len(labels)  # è®¡ç®—æ ·æœ¬æ€»æ•°\n",
    "        self.prior_prob = {label: count / num_samples for label, count in label_counts.items()}  # è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„å…ˆéªŒæ¦‚ç‡\n",
    "        \n",
    "        # è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„ç¬¬iä¸ªç‰¹å¾çš„å‡å€¼muå’Œæ ‡å‡†å·®std\n",
    "        # ç”¨æ ·æœ¬å‡å€¼å’Œæ ‡å‡†å·®æ¥è¿›è¡Œä¼°è®¡\n",
    "        self.mu = {}; self.std = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.mu[label] = {}; self.std[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                mu = np.mean(feature_values); std = np.std(feature_values)\n",
    "                self.mu[label][feature_index] = mu\n",
    "                self.std[label][feature_index] = std\n",
    "        \n",
    "    \n",
    "        # è®¡ç®—æ¡ä»¶æ¦‚ç‡\n",
    "        self.conditional_prob = {}\n",
    "        self.num_values = {}\n",
    "        for label in label_counts.keys():\n",
    "            self.conditional_prob[label] = {}\n",
    "            for feature_index in range(len(data[0])):\n",
    "                label_indexes = np.where(labels == label)[0]\n",
    "                feature_values = data[label_indexes, feature_index]\n",
    "                self.num_values[feature_index] = len(feature_values)\n",
    "                value_counts = Counter(feature_values)\n",
    "                self.conditional_prob[label][feature_index] = {value: self.gauss(value, self.mu[label][feature_index], self.std[label][feature_index]) for value in value_counts.keys()}\n",
    "        return self\n",
    "    # é¢„æµ‹å‡½æ•°\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        å‡½æ•°è¯´æ˜:\n",
    "            - ç»™å®šç‰¹å¾å€¼ï¼Œé¢„æµ‹ç±»åˆ«\n",
    "        parameters:\n",
    "            - data æµ‹è¯•ç‰¹å¾å‘é‡\n",
    "        return:\n",
    "            - self\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        for sample in data:\n",
    "            # è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„æ¦‚ç‡\n",
    "            label_prob = {label: self.prior_prob[label] for label in self.prior_prob.keys()}\n",
    "            for label in self.prior_prob.keys():\n",
    "                for feature_index in range(len(sample)):\n",
    "                    feature_value = sample[feature_index]\n",
    "                    # label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    if feature_value in self.conditional_prob[label][feature_index].keys():\n",
    "                        label_prob[label] *= self.conditional_prob[label][feature_index][feature_value]\n",
    "                    else:\n",
    "                        # label_prob[label] = 0\n",
    "                        # æ‹‰æ™®æ‹‰æ–¯ä¿®æ­£\n",
    "                        label_prob[label] *= 1 / (2*self.num_values[feature_index])\n",
    "            # æ ¹æ®æ¦‚ç‡é€‰æ‹©æœ€å¤§çš„æ ‡ç­¾\n",
    "            labels.append(max(label_prob, key=label_prob.get))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0a3bae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_C:\t [0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
      "y_pred_D:\t [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
      "y_test:\t\t [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    fileName = './work/2021å†¬æ¨¡å¼è¯†åˆ«æ•°æ®æ”¶é›†.xlsx'\n",
    "    data = load_data(fileName)\n",
    "    X = data.iloc[:, 1:]\n",
    "    y = data.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=8)\n",
    "    X_train = X_train.values; X_test = X_test.values\n",
    "    y_train = y_train.values; y_test = y_test.values\n",
    "    NBC = NaiveBayesClassifierContinuous()\n",
    "    NBD = NaiveBayesClassifierDiscrete()\n",
    "    NBC.data = X_train; NBC.labels = y_train\n",
    "    NBD.data = X_train; NBD.labels = y_train\n",
    "    NBC.fit(X_train, y_train); NBD.fit(X_train, y_train)\n",
    "    y_pred_C = NBC.predict(X_test)\n",
    "    y_pred_D = NBD.predict(X_test)\n",
    "    print('y_pred_C:\\t', y_pred_C)\n",
    "    print('y_pred_D:\\t', y_pred_D)\n",
    "    print('y_test:\\t\\t', list(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02904be2",
   "metadata": {},
   "source": [
    "## 4. æ¯”è¾ƒæ£€éªŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d28084e",
   "metadata": {},
   "source": [
    "### 4.1. äºŒé¡¹æ£€éªŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14117402",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47a489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values; X_test = X_test.values\n",
    "y_train = y_train.values; y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2f911b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBD.fit(X_train, y_train)\n",
    "y_pred = NBD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d4124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errCount = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        errCount += 1\n",
    "errRate = errCount/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b69d87ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.09090909090909091"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b673ff6",
   "metadata": {},
   "source": [
    "> å‡è®¾æ¨¡å‹çš„æ³›åŒ–é”™è¯¯ç‡å°äº42%ï¼Œ\n",
    ">\n",
    "> å³$H_0: \\epsilon < 0.42$\n",
    ">\n",
    "$$\n",
    "P(\\hat{\\epsilon};\\epsilon)=C_{m}^n \\epsilon^m(1-\\epsilon)^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee6533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b91854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbbcd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "epsilon = 0.42\n",
    "for n in range(m+1):\n",
    "    p = math.comb(m, n)*(epsilon**m)*((1-epsilon)**n)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a7174d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.010989303071931383"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b31bf457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(list(range(m+1)),P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a43646",
   "metadata": {},
   "source": [
    "> æ˜¾è‘—æ€§æ°´å¹³$1-\\alpha = 0.99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bb97dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7924626856583731e-07\n",
      "3.578744465504131e-06\n",
      "3.288476340462735e-05\n",
      "0.00018446761998629912\n",
      "0.0007071671254403396\n",
      "0.0019688555868811273\n",
      "0.004144180520399726\n",
      "0.006823152113402926\n",
      "0.00913261038323327\n",
      "0.01045988525095186\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "acc = 0\n",
    "for i in reversed(list(range(m+1))):\n",
    "    acc += P[i]\n",
    "    print(acc)\n",
    "    if acc > alpha:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96dde5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad361b",
   "metadata": {},
   "source": [
    "> è½åœ¨ç½®ä¿¡åŒºé—´å†…\n",
    ">\n",
    "> ä»¥99%çš„ç½®ä¿¡æ°´å¹³è®¤ä¸ºï¼Œæ¨¡å‹åˆ†æ³›åŒ–é”™è¯¯ç‡å°äº42%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c308e",
   "metadata": {},
   "source": [
    "### 4.2. tæ£€éªŒ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76bc3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "433bfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "errRate = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    NBD.fit(X_train, y_train)\n",
    "    y_pred = NBD.predict(X_test)\n",
    "    errCount = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred[i] != y_test[i]:\n",
    "            errCount += 1\n",
    "    errRate.append(errCount/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed883a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0.09090909090909091, 0.0, 0.1, 0.2, 0.0]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82806c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(errRate)\n",
    "sigma = np.var(errRate, ddof = 1) # ä¿®æ­£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b4da23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.07818181818181819"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686d08e8",
   "metadata": {},
   "source": [
    "> $H_0: \\epsilon=0.08$\n",
    ">\n",
    "> $\\alpha = 0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4b73d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t = \\frac{\\sqrt{k}(\\mu -\\epsilon_0)}{\\sigma}\n",
    "$$\n",
    "æœä»è‡ªç”±åº¦ä¸º$k-1$çš„$t$åˆ†å¸ƒ\n",
    "![](https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/427a4d0c7f7fdb96f41962d7289fe29.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ed285b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.08\n",
    "k = len(y_pred)\n",
    "t = np.sqrt(k)*(mu - epsilon)/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6df0a506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-0.8301922258198599"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2bf99",
   "metadata": {},
   "source": [
    "> ä»¥90%çš„ç½®ä¿¡åº¦è®¤ä¸ºæ¨¡å‹çš„æ³›åŒ–é”™è¯¯ç‡ç­‰äº8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609356a",
   "metadata": {},
   "source": [
    "### 4.3. äº¤å‰éªŒè¯tæ£€éªŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87eb8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afde0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBC = NaiveBayesClassifierContinuous()\n",
    "errRateD = []; errRateC = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "    y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "    errCount_D = 0; errCount_C = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred_D[i] != y_test[i]:\n",
    "            errCount_D += 1\n",
    "        if y_pred_C[i] != y_test[i]:\n",
    "            errCount_C += 1\n",
    "    errRateD.append(errCount_D/len(y_pred))\n",
    "    errRateC.append(errCount_C/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64038eb",
   "metadata": {},
   "source": [
    "> $H_0$: ä¸¤æ¨¡å‹æ€§èƒ½ç›¸å½“\n",
    ">\n",
    "> $\\alpha=0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4124f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t=|\\frac{\\sqrt{k}\\mu}{\\sigma}|\n",
    "$$\n",
    "ä¸´ç•Œå€¼$t_{\\alpha/2,k-1}=2.262$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58f7ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "errRateDelta = np.array(errRateD) - np.array(errRateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dedf23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(y_pred)\n",
    "mu = errRateDelta.mean()\n",
    "sigma = errRateDelta.var(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dac24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.abs(np.sqrt(k)*mu/sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b897c9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "36.14031611621005"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd56c6",
   "metadata": {},
   "source": [
    "> $t>2.262$ æ‹’ç»åŸå‡è®¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90488a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.16"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errRateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23c40f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.08"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errRateD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc0ba6",
   "metadata": {},
   "source": [
    "> ä¸¤å­¦ä¹ å™¨æœ‰æ˜¾è‘—çš„å·®åˆ« \n",
    ">\n",
    "> ç¦»æ•£å‹å¹³å‡é”™è¯¯ç‡è¾ƒå°ï¼Œè®¤ä¸ºå…¶æ€§èƒ½è¾ƒä¼˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc4d1fd",
   "metadata": {},
   "source": [
    "**é‡‡ç”¨$5\\times 2$æŠ˜äº¤å‰éªŒè¯**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7b3dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete()\n",
    "NBC = NaiveBayesClassifierContinuous()\n",
    "errRateDD = []; errRateCC = []\n",
    "for i in range(5):\n",
    "    errRateD = []; errRateC = []\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=i) # äº”æ¬¡éšæœº\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "        NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "        y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "        errCount_D = 0; errCount_C = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_pred_D[i] != y_test[i]:\n",
    "                errCount_D += 1\n",
    "            if y_pred_C[i] != y_test[i]:\n",
    "                errCount_C += 1\n",
    "        errRateD.append(errCount_D/len(y_pred))\n",
    "        errRateC.append(errCount_C/len(y_pred))\n",
    "    errRateDD.append(errRateD); errRateCC.append(errRateC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1392be0e",
   "metadata": {},
   "source": [
    "ä¸ºäº†ç¼“è§£æµ‹è¯•é”™è¯¯ç‡çš„éç‹¬ç«‹æ€§ï¼Œä»…è®¡ç®—ç¬¬ä¸€æ¬¡çš„2æŠ˜äº¤å‰éªŒè¯çš„å¹³å‡å€¼$\\mu$ï¼Œå’Œæ¯æ¬¡çš„æ–¹å·®\n",
    "$$\n",
    "Î¼=0.5Ã—(Î”_ğ‘–^1+Î”_ğ‘–^2 )\\\\\n",
    "Ïƒ_ğ‘–^2=(Î”_ğ‘–^1âˆ’\\frac{Î”_ğ‘–^1+Î”_ğ‘–^2}{2})^2+(Î”_ğ‘–^1âˆ’\\frac{Î”_ğ‘–^2+Î”_ğ‘–^2}{2})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4386a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "errRateDelta = np.array(errRateCC) - np.array(errRateDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63d419bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.5, 0.2],\n       [1.2, 0.4],\n       [0.8, 0.6],\n       [0.5, 0. ],\n       [0.5, 0.1]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errRateDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "420a5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(errRateDelta[0])\n",
    "sigma = np.var(errRateDelta, axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e18a83",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tau_t=\\frac{\\mu}{\\sqrt{0.2\\sum_{i=1}^{5}\\sigma_i^2}}\n",
    "$$\n",
    "æœä»è‡ªç”±åº¦ä¸º5çš„$t$åˆ†å¸ƒï¼Œä¸´ç•Œå€¼$t_{\\alpha/2,5}$\n",
    "\n",
    "$\\alpha=0.1$æ—¶ï¼Œ$t_{\\alpha/2,5}=2.776$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25ea03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mu/np.sqrt(0.2*sum(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bc95d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.0188893920442685"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd03ca0",
   "metadata": {},
   "source": [
    "> å°äºä¸´ç•Œå€¼ï¼Œè®¤ä¸ºä¸¤å­¦ä¹ å™¨æ²¡æœ‰æ˜¾è‘—å·®åˆ«"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc8e75",
   "metadata": {},
   "source": [
    "### 4.4. McNemaræ£€éªŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabea927",
   "metadata": {},
   "source": [
    "**åˆ—è”è¡¨**\n",
    "![](https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/20221214214255.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "181607f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "y_train, y_test = y.values[train_index], y.values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba318484",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBD = NaiveBayesClassifierDiscrete() # å­¦ä¹ å™¨A\n",
    "NBC = NaiveBayesClassifierContinuous()# å­¦ä¹ å™¨B\n",
    "errCount_D = 0; errCount_C = 0\n",
    "\n",
    "NBD.fit(X_train, y_train); NBC.fit(X_train, y_train)\n",
    "y_pred_D = NBD.predict(X_test); y_pred_C = NBC.predict(X_test)\n",
    "conTable = np.zeros([2,2])\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_D[i] == 1:\n",
    "        if y_pred_C[i] == 1:\n",
    "            conTable[0][0] += 1\n",
    "        else:\n",
    "            conTable[1][0] += 1\n",
    "    else:\n",
    "        if y_pred_C[i] == 1:\n",
    "            conTable[0][1] += 1\n",
    "        else:\n",
    "            conTable[1][1] += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "380f5dd0",
   "metadata": {},
   "source": [
    "> $H_0: e_{01}=e_{10}$\n",
    "$$\n",
    "Ï„_{Ï‡^2 }=\\frac{(ğ‘âˆ’ğ‘)^2}{ğ‘+ğ‘}\n",
    "$$\n",
    "æœä»è‡ªç”±åº¦ä¸º1çš„å¡æ–¹åˆ†å¸ƒ\n",
    ">\n",
    "> $\\alpha =0.05$æ—¶ï¼Œä¸´ç•Œå€¼ä¸º3.8415\n",
    ">\n",
    "> $\\alpha =0.1$æ—¶ï¼Œä¸´ç•Œå€¼ä¸º2.7055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b2dc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chis = (conTable[0][1] - conTable[1][0])**2/(conTable[0][1] + conTable[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac995f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79813188",
   "metadata": {},
   "source": [
    "> å°äºä¸´ç•Œå€¼ï¼Œä»¥95%çš„ç½®ä¿¡åº¦è®¤ä¸ºï¼Œä¸¤å­¦ä¹ å™¨çš„æ€§èƒ½æ²¡æœ‰æ˜¾è‘—å·®åˆ«"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**è®¡ç®—F1-score**\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}$$$$\n",
    "Recall = \\frac{TP}{TP + FN}$$$$\n",
    "F-score = \\frac{2Precision * Recall}{Precision + Recall}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# è®¡ç®—æ··æ·†çŸ©é˜µå„ç±»åˆ«é¢‘æ•°\n",
    "def get_confusion_matrix(y_true, y_pred, flag = 1):\n",
    "    tn = tp = fn = fp = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            if y_pred[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if y_pred[i] == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    if flag == 1:\n",
    "        return tn ,tp, fn, fp\n",
    "    else:\n",
    "        return tp, tn, fp, fn\n",
    "\n",
    "\n",
    "def get_precision(tp, fp):\n",
    "    if tp == 0:\n",
    "        return 0.0\n",
    "    return float(tp) / float(tp + fp)\n",
    "\n",
    "\n",
    "def get_recall(tp, fn):\n",
    "    if tp == 0:\n",
    "        return 0.0\n",
    "    return float(tp) / float(tp + fn)\n",
    "\n",
    "\n",
    "def get_fscore(tp, fp, fn):\n",
    "    precision = get_precision(tp, fp)\n",
    "    recall = get_recall(tp, fn)\n",
    "    try:\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "    except:\n",
    "        return 0.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‰¹å¾ä¸ºï¼š èº«é«˜ ä½“é‡ è„šé•¿ å°ºç  \n",
      "\tf1-score\n",
      "0\t0.750000\n",
      "1\t0.333333\n"
     ]
    }
   ],
   "source": [
    "def display_f1score(ch = [1, 2, 3, 4], method = NaiveBayesClassifierDiscrete):\n",
    "    name = ['', 'èº«é«˜', 'ä½“é‡', 'è„šé•¿', 'å°ºç ']\n",
    "    fileName = './work/2021å†¬æ¨¡å¼è¯†åˆ«æ•°æ®æ”¶é›†.xlsx'\n",
    "    data = load_data(fileName)\n",
    "    X = data.iloc[:, ch]\n",
    "    y = data.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=8)\n",
    "    X_train = X_train.values; X_test = X_test.values\n",
    "    y_train = y_train.values; y_test = y_test.values\n",
    "    NBD = method()\n",
    "    NBD.data = X_train; NBD.labels = y_train\n",
    "    NBD.fit(X_train, y_train)\n",
    "    y_pred_D = NBD.predict(X_test)\n",
    "    print('ç‰¹å¾ä¸ºï¼š', end = ' ')\n",
    "    for item in ch:\n",
    "        print(name[item], end=' ')\n",
    "    print()\n",
    "    tn0, tp0, fn0, fp0 = get_confusion_matrix(y_test, y_pred_D, 0)\n",
    "    tn1, tp1, fn1, fp1 = get_confusion_matrix(y_test, y_pred_D, 1)\n",
    "    print('\\tf1-score\\n0\\t%f\\n1\\t%f'%(get_fscore(tp0, fp0, fn0), get_fscore(tp1, fp1, fn1)))\n",
    "\n",
    "# é€‰æ‹©ç‰¹å¾å’Œåˆ†ç±»å™¨\n",
    "display_f1score([1, 2, 3, 4], NaiveBayesClassifierContinuous)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
