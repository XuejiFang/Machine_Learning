## 0. 先说结论

实验采用了离散属性和连续属性的朴素贝叶斯分类器，基于“2021冬模式识别数据收集.xlsx”，以身高、体重、脚长、尺码作为特征，来对性别进行预测。

**以下结论只是在该具体问题下得出来的**。

| 检验方法                   | 统计量or公式                                                 | 分类器 | 原假设           | $\alpha$ | 结论                                                 |
| -------------------------- | ------------------------------------------------------------ | ------ | ---------------- | -------- | ---------------------------------------------------- |
| 二项检验                   | $P(\hat{\epsilon};\epsilon)=C_{m}^n \epsilon^m(1-\epsilon)^n$ | 离散型 | $\epsilon< 0.1$  | 0.1      | 在**90%的置信水平**下，认为模型**泛化错误率小于10%** |
| t检验                      | $\tau_t = \frac{\sqrt{k}(\mu -\epsilon_0)}{\sigma}$          | 离散型 | $\epsilon= 0.08$ | 0.1      | 在**90%的置信水平**下，认为模型**泛化错误率等于8%**  |
| 交叉验证t检验              | $\tau_t=|\frac{\sqrt{k}\mu}{\sigma}|$                        | both   | 两者性能相当     | 0.1      | 拒绝原假设，且离散型性能更优                         |
| $5\times 2$折交叉验证t检验 | $\tau_t=\frac{\mu}{\sqrt{0.2\sum_{i=1}^{5}\sigma_i^2}}$      | both   | 两者性能相当     | 0.1      | 接受原假设，两者性能相当                             |
| McNemar检验                | $τ_{χ^2 }=\frac{(𝑏−𝑐)^2}{𝑏+𝑐}$                               | both   | 两者性能相当     | 0.1      | 接受原假设，两者性能相当                             |

**不同检验方法适用情况**

| 检验方法                      | 测试集 | 模型/算法 |
| ----------------------------- | :----- | --------- |
| 二项检验                      | 1      | 1         |
| t检验                         | 多个   | 1         |
| 交叉验证t检验                 | 多个   | 2         |
| McNemar检验                   | 1      | 2         |
| Friedman检验、Nemenyi后续检验 | 多个   | 多种      |

## 1. 二项检验

对于一个学习器，测试错误率$ϵ ̂$，泛化错误率$ϵ$，测试样本数$m$

则，误分类样本数$m^′=ϵ ̂×m$

那么，泛化错误率$ϵ$的学习器将$m^′$个样本误分类，其余正确的概率就是
$$
P(ϵ ̂;ϵ)=C_m^{m^′} ϵ^{m^′} (1-ϵ)^{m-m^′}
$$
这符合二项分布。

**举个栗子**

对于给定假设$H_0:ϵ≤ϵ_0=0.3$，且$m=10 $和置信水平$1-α$

$α$一般取0.05、0.1，图中是为了方便绘图

<img src="https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/image-20221221141216176.png" alt="image-20221221141216176" style="zoom:50%;" />

临界值为：
$$
\overline{\epsilon}=\max\ \epsilon\ s.t.\ \sum_{i=\epsilon_0\times m+1}^m C_m^i\epsilon^i(1-\epsilon)^{m-i}<\alpha
$$
如果此时测试错误率$ϵ ̂<\overlineϵ$，可以得出：

在$α$的显著度下，接受原假设，即能以$1-α$的置信度认为 $ϵ≤0.3$ ；

反之，拒绝原假设

## 2. t检验

**多次重复留出法**or**交叉验证法**，得到多个测试集，因而有多个测试错误率

对于给定k 个测试错误率$ϵ_1 ̂,ϵ_2  ̂,⋯,ϵ_k  ̂$，得

平均测试错误率
$$
 μ=\frac{1}{k} ∑_{i=1}^kϵ_i  ̂ 
$$
测试错误率方差
$$
σ^2=\frac{1}{n-1} ∑_{i=1}^k(ϵ_i  ̂-μ)^2
$$
考虑到，这k 个测试错误率可以看作是泛化错误率$ϵ$的独立采样，可以采用统计量
$$
\tau_t = \frac{\sqrt{k}(\mu -\epsilon_0)}{\sigma}
$$
服从自由度为$k-1$的$t$分布

<img src="https://jaggar-oss.oss-cn-shanghai.aliyuncs.com/img/image-20221221141754553.png" alt="image-20221221141754553" style="zoom:50%;" />

> 图为双边t检验

## 3. 交叉验证t检验

对于两个学习器A 和B ，若使用k 折交叉验证法得到的测试错误率分别为$ϵ_1^A  ̂,ϵ_2^A  ̂,⋯,ϵ_k^A  ̂和 ϵ_1^B  ̂,ϵ_2^B  ̂,⋯,ϵ_k^B  ̂$，其中$ϵ_i^A$和$ϵ_i^B$ 是在相同的第*i* 折训练或预测集上得到的结果，则可以采用k 折交叉验证“成对t 检验”（paired t-test）来进行比较检验

**基本思想**

若两个学习器的性能相同，那么它们使用相同的训练集或测试集得到的错误率应当相同，即$ϵ_i^A=ϵ_i^B$



记差值$Δ_i=ϵ_i^A-ϵ_i^B$，假设“A和B的性能相同”，则差值的均值应当为0，相当于

原假设$H_0:EΔ=0$

令测试集的差值的均值和方差分别为μ和σ，构建统计量
$$
τ_t=|\frac{\sqrt{k} {(μ-0)}}{σ}|=|\frac{\sqrt{k} {μ}}{σ}|
$$
小于临界值$t_{\frac{α}{2},k-1}$, 则接受原假设，即认为两个学习器的性能没有显著差别；

否则可认为两个学习器的性能有显著差别，且平均错误率较小的那个学习器性能较优。

**重要前提**

测试错误率均为泛化错误率的独立采样

> 一般不满足该前提条件，Dietterich提出采用5$\times$ 2折交叉验证

记第i 次的2 折交叉验证中的第1 折交叉验证和第2 折交叉验证的差值分别为$Δ_i^1$和$Δ_i^2$，那么第i 次的2 折交叉验证的差值的平均值和方差为
$$
μ_i=0.5×(Δ_i^1+Δ_i^2 )
$$

$$
σ_i^2=(\frac{Δ_i^1-(Δ_i^1+Δ_i^2)}{2})^2+(\frac{Δ_i^1-(Δ_i^2+Δ_i^2)}{2})^2
$$

那么，构造出统计量
$$
\tau_{t}=\frac{\sqrt{5} \mu}{\sqrt{\sum_{i=1}^{5} \sigma_{i}^{2}}}=\frac{\mu}{\sqrt{0.2 \sum_{i=1}^{5} \sigma_{i}^{2}}}
$$
它服从自由度为5 的t 分布，其双边检验的临界值$t_{\frac{α}{2},5}$

## 4. **McNemar**检验

对于二分类问题，留出法不仅可以给出学习器A和B的测试错误率，还可获得两学习器分类结果的差别，即两者都正确、都错误、一个正确另一个错误的样本数用**列联表**(contingency table)表示为

|                     | **Test 2 positive** | **Test 2 negative** | **Row total** |
| ------------------- | ------------------- | ------------------- | ------------- |
| **Test 1 positive** | a                   | b                   | a + b         |
| **Test 1 negative** | c                   | d                   | c + d         |
| **Column total**    | a + c               | b + d               | N             |

如果假设两学习器性能相同，则原假设$H_0:b=c$

构建出统计量
$$
τ_(χ^2 )=\frac{(b-c)^2}{b+c}
$$
它服从自由度为1 的卡方分布。对于给定的显著度α，如果算得上变量值小于临界值$χ_α^2$，则接受原假设，即认为两学习器的性能没有显著差别；否则拒绝假设，即认为两者性能有显著差别，且平均错误率较小的那个学习器性能较优。

自由度为1 的$χ^2$检验的临界值

α=0.05→3.8415

α=0.1→2.7055